<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SpringMVC拦截器]]></title>
    <url>%2F2017%2F08%2F14%2FSpringMVC%E6%8B%A6%E6%88%AA%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Spring MVC中的拦截器（Interceptor）类似于Servlet中的过滤器（Filter），它主要用于拦截用户请求并作相应的处理。通过拦截器可以进行权限验证、记录请求信息的日志、判断用户是否登录等。 ## SpringMVC 拦截器原理图 ![](https://i.imgur.com/dEKEE0i.jpg) 注意postHandle方法的执行顺序与定义顺序正好相反。 SpringMVC 中的Interceptor 拦截请求是通过HandlerInterceptor 来实现的。在SpringMVC 中定义一个Interceptor 主要有两种方式. 第一种方式是要定义的Interceptor类要实现了Spring 的HandlerInterceptor 接口，或者是这个类继承实现了HandlerInterceptor 接口的类，如Spring已经提供的实现了HandlerInterceptor 接口的抽象类HandlerInterceptorAdapter; 第二种方式是实现Spring的WebRequestInterceptor接口，或者是继承实现了WebRequestInterceptor的类。 实现HandlerInterceptor接口HandlerInterceptor 接口中定义了三个方法，我们就是通过这三个方法来对用户的请求进行拦截处理的。流程：接口实现如下：1234567891011121314151617181920212223242526272829303132333435363738public class SpringMVCInterceptor implements HandlerInterceptor &#123; /** * preHandle方法是进行处理器拦截用的，该方法将在Controller处理之前进行调用，SpringMVC中的Interceptor拦截器是链式的，可以同时存在 * 多个Interceptor，然后SpringMVC会根据声明的前后顺序一个接一个的执行，而且所有的Interceptor中的preHandle方法都会在 * Controller方法调用之前调用。SpringMVC的这种Interceptor链式结构也是可以进行中断的，这种中断方式是令preHandle的返 * 回值为false，当preHandle的返回值为false的时候整个请求就结束了。 */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // TODO Auto-generated method stub return false; &#125; /** * 这个方法只会在当前这个Interceptor的preHandle方法返回值为true的时候才会执行。postHandle是进行处理器拦截用的，它的执行时间是在处理器进行处理之 * 后，也就是在Controller的方法调用之后执行，但是它会在DispatcherServlet进行视图的渲染之前执行，也就是说在这个方法中你可以对ModelAndView进行操 * 作。这个方法的链式结构跟正常访问的方向是相反的，也就是说先声明的Interceptor拦截器该方法反而会后调用。 */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; // TODO Auto-generated method stub &#125; /** * 该方法也是需要当前对应的Interceptor的preHandle方法的返回值为true时才会执行。该方法将在整个请求完成之后，也就是DispatcherServlet渲染了视图执行， * 这个方法的主要作用是用于清理资源的，当然这个方法也只能在当前这个Interceptor的preHandle方法的返回值为true时才会执行。 */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; // TODO Auto-generated method stub &#125; &#125; preHandle：预处理回调方法，实现处理器的预处理（如登录检查），第三个参数为响应的处理器（如我们上一章的Controller实现）； 返回值：true表示继续流程（如调用下一个拦截器或处理器）;false表示流程中断（如登录检查失败），不会继续调用其他的拦截器或处理器，此时我们需要通过response来产生响应； postHandle：后处理回调方法，实现处理器的后处理（但在渲染视图之前），此时我们可以通过modelAndView（模型和视图对象）对模型数据进行处理或对视图进行处理，modelAndView也可能为null。 afterCompletion：整个请求处理完毕回调方法，即在视图渲染完毕时回调，如性能监控中我们可以在此记录结束时间并输出消耗时间，还可以进行一些资源清理，类似于try-catch-finally中的finally，但仅调用处理器执行链中preHandle返回true的拦截器的afterCompletion。在实际应用中，一般都是通过实现HandlerInterceptor接口或者继承HandlerInterceptorAdapter抽象类，复写preHandle()、postHandle()和afterCompletion()这 3 个方法来对用户的请求进行拦截处理的。 WebRequestInterceptor 接口在WebRequestInterceptor接口中也定义了 3 个方法，同HandlerInterceptor接口完全相同，也是通过复写这 3 个方法来用户的请求进行拦截处理的。而且这 3 个方法都传递了同一个参数 WebRequest，这个 WebRequest 是 Spring 中定义的一个接口，它里面的方法定义跟 HttpServletRequest 类似，在WebRequestInterceptor中对 WebRequest 进行的所有操作都将同步到 HttpServletRequest 中，然后在当前请求中依次传递。在 Spring 框架之中，还提供了一个和WebRequestInterceptor接口长的很像的抽象类，那就是：WebRequestInterceptorAdapter，其实现了AsyncHandlerInterceptor接口，并在内部调用了WebRequestInterceptor接口。接下来，咱们主要讲一下WebRequestInterceptor接口的 3 个函数： preHandle(WebRequest request)方法，该方法在请求处理之前进行调用，即在 Controller 中的方法调用之前被调用。这个方法跟 HandlerInterceptor 中的 preHandle 不同，主要区别在于该方法的返回值是void 类型的，也就是没有返回值，因此我们主要用它来进行资源的准备工作。在这里，进一步说说 setAttribute 方法的第三个参数 scope ，该参数是一个Integer 类型的。在 WebRequest 的父层接口 RequestAttributes 中对它定义了三个常量，分别为： SCOPE_REQUEST ，它的值是 0，表示只有在 request 中可以访问。 SCOPE_SESSION，它的值是1，如果环境允许的话，它表示的是一个局部的隔离的 session，否则就代表普通的 session，并且在该 session 范围内可以访问。 SCOPE_GLOBAL_SESSION，它的值是 2，如果环境允许的话，它表示的是一个全局共享的 session，否则就代表普通的 session，并且在该 session 范围内可以访问。 postHandle(WebRequest request, ModelMap model)方法，该方法在请求处理之后，也就是在 Controller 中的方法调用之后被调用，但是会在视图返回被渲染之前被调用，所以可以在这个方法里面通过改变数据模型 ModelMap 来改变数据的展示。该方法有两个参数，WebRequest 对象是用于传递整个请求数据的，比如在 preHandle 中准备的数据都可以通过 WebRequest 来传递和访问；ModelMap 就是 Controller 处理之后返回的 Model 对象，咱们可以通过改变它的属性来改变返回的 Model 模型。 afterCompletion(WebRequest request, Exception ex)方法，该方法会在整个请求处理完成，也就是在视图返回并被渲染之后执行。因此可以在该方法中进行资源的释放操作。而 WebRequest 参数就可以把咱们在 preHandle 中准备的资源传递到这里进行释放。Exception 参数表示的是当前请求的异常对象，如果在 Controller 中抛出的异常已经被 Spring 的异常处理器给处理了的话，那么这个异常对象就是是 null.123456789101112131415161718192021import org.springframework.ui.ModelMap;import org.springframework.web.context.request.WebRequest;import org.springframework.web.context.request.WebRequestInterceptor;public class WrongCodeInterceptor implements WebRequestInterceptor &#123; @Override public void preHandle(WebRequest request) throws Exception &#123; System.out.println("WrongCodeInterceptor, preHandle......"); &#125; @Override public void postHandle(WebRequest request, ModelMap model) throws Exception &#123; System.out.println("WrongCodeInterceptor, postHandle......"); &#125; @Override public void afterCompletion(WebRequest request, Exception ex) throws Exception &#123; System.out.println("WrongCodeInterceptor, afterCompletion......"); &#125;&#125; 拦截器的配置123456789&lt;mvc:interceptors&gt; &lt;!-- 使用bean定义一个Interceptor，直接定义在mvc:interceptors根下面的Interceptor将拦截所有的请求 --&gt; &lt;bean class="com.host.app.web.interceptor.AllInterceptor"/&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/test/number.do"/&gt; &lt;!-- 定义在mvc:interceptor下面的表示是对特定的请求才进行拦截的 --&gt; &lt;bean class="com.host.app.web.interceptor.LoginInterceptor"/&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 实例1：SpringMVC拦截器实现登录认证控制器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * 登录认证的控制器 */ @Controller public class LoginControl &#123; /** * 登录 * @param session * HttpSession * @param username * 用户名 * @param password * 密码 * @return */ @RequestMapping(value="/login") public String login(HttpSession session,String username,String password) throws Exception&#123; //在Session里保存信息 session.setAttribute("username", username); //重定向 return "redirect:hello.action"; &#125; /** * 退出系统 * @param session * Session * @return * @throws Exception */ @RequestMapping(value="/logout") public String logout(HttpSession session) throws Exception&#123; //清除Session session.invalidate(); return "redirect:hello.action"; &#125; &#125; ``` 拦截器：```java/** * 登录认证的拦截器 */ public class LoginInterceptor implements HandlerInterceptor&#123; /** * Handler执行完成之后调用这个方法 */ public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception exc) throws Exception &#123; &#125; /** * Handler执行之后，ModelAndView返回之前调用这个方法 */ public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; /** * Handler执行之前调用这个方法 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //获取请求的URL String url = request.getRequestURI(); //URL:login.jsp是公开的;这个demo是除了login.jsp是可以公开访问的，其它的URL都进行拦截控制 if(url.indexOf("login.action")&gt;=0)&#123; return true; &#125; //获取Session HttpSession session = request.getSession(); String username = (String)session.getAttribute("username"); if(username != null)&#123; return true; &#125; //不符合条件的，跳转到登录界面 request.getRequestDispatcher("/WEB-INF/jsp/login.jsp").forward(request, response); return false; &#125; &#125; 在spring的配置文件中配置这个拦截器 &lt;!-- 拦截器 --&gt; &lt;mvc:interceptors&gt; &lt;!-- 多个拦截器，顺序执行 --&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/**"/&gt; &lt;bean class="com.mvc.interceptor.LoginInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 此外，也可在postHandle和afterCompletion中定义拦截逻辑，其中postHandle处理尚未渲染的ModelAndView数据，afterCompletion中处理后置的一些验证等操作. 实例2 性能监控如记录一下请求的处理时间，得到一些慢请求（如处理时间超过500毫秒），从而进行性能改进，一般的反向代理服务器如apache都具有这个功能，但此处我们演示一下使用拦截器怎么实现。实现分析：1、在进入处理器之前记录开始时间，即在拦截器的preHandle记录开始时间；2、在结束请求处理之后记录结束时间，即在拦截器的afterCompletion记录结束实现，并用结束时间-开始时间得到这次请求的处理时间。问题：我们的拦截器是单例，因此不管用户请求多少次都只有一个拦截器实现，即线程不安全，那我们应该怎么记录时间呢？解决方案是使用ThreadLocal，它是线程绑定的变量，提供线程局部变量（一个线程一个ThreadLocal，A线程的ThreadLocal只能看到A线程的ThreadLocal，不能看到B线程的ThreadLocal）。 public class StopWatchHandlerInterceptor extends HandlerInterceptorAdapter { private NamedThreadLocal&lt;Long&gt; startTimeThreadLocal = new NamedThreadLocal&lt;Long&gt;("StopWatch-StartTime"); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { long beginTime = System.currentTimeMillis();//1、开始时间 startTimeThreadLocal.set(beginTime);//线程绑定变量（该数据只有当前请求的线程可见） return true;//继续流程 } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { long endTime = System.currentTimeMillis();//2、结束时间 long beginTime = startTimeThreadLocal.get();//得到线程绑定的局部变量（开始时间） long consumeTime = endTime - beginTime;//3、消耗的时间 if(consumeTime &gt; 500) {//此处认为处理时间超过500毫秒的请求为慢请求 //TODO 记录到日志文件 System.out.println( String.format("%s consume %d millis", request.getRequestURI(), consumeTime)); } } } NamedThreadLocal：Spring提供的一个命名的ThreadLocal实现。在测试时需要把stopWatchHandlerInterceptor放在拦截器链的第一个，这样得到的时间才是比较准确的。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>拦截器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java源码--ArrayDeque]]></title>
    <url>%2F2017%2F08%2F14%2Fjava%E6%BA%90%E7%A0%81-ArrayDeque%2F</url>
    <content type="text"><![CDATA[概述Deque意为双端队列，ArrayDeque显然是基于数组实现的双端队列，而且作为双端队列时，效率比LinkList高。而且其特性使它还可以当做栈来使用，效率比Stack高。ArrayDeque是非线程安全的（not thread-safe），当多个线程同时使用的时候，需要程序员手动同步；另外，该容器不允许放入null元素。继承体系：12public class ArrayDeque&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Deque&lt;E&gt;, Cloneable, Serializable 存储结构从内部存储上，可以看到内部只有一个数组12345678// 底层用数组存储元素 private transient E[] elements; // 队列的头部元素索引（即将pop出的一个） private transient int head; // 队列下一个要添加的元素索引 ，注意是下一个，不是最后一个元素 private transient int tail; // 最小的初始化容量大小，需要为2的n次幂 private static final int MIN_INITIAL_CAPACITY = 8; 上图中我们看到，head指向首端第一个有效元素，tail指向尾端第一个可以插入元素的空位，不是当前数组的元素位置。因为是循环数组，所以head不一定总等于0，tail也不一定总是比head大。 构造方法12345678910111213141516171819202122 /** * 默认构造方法，数组的初始容量为16 */ public ArrayDeque() &#123; elements = (E[]) new Object[16]; &#125; /** * 使用一个指定的初始容量构造一个ArrayDeque,但是最终分配的容量并不是numElements，初始容量是大于指定numElements的最小的2的n次幂 */ public ArrayDeque( int numElements) &#123; allocateElements(numElements); &#125; /** * 构造一个指定Collection集合参数的ArrayDeque */ public ArrayDeque(Collection&lt;? extends E&gt; c) &#123; allocateElements(c.size()); addAll(c); &#125; allocateElements()是什么东西呢？ 1234567891011121314151617181920212223/** * 分配合适容量大小的数组，确保初始容量是大于指定numElements的最小的2的n次幂 */ private void allocateElements(int numElements) &#123; int initialCapacity = MIN_INITIAL_CAPACITY; //初始容量为8 // 找到大于指定容量的最小的2的n次幂 // Find the best power of two to hold elements. // Tests "&lt;=" because arrays aren't kept full. // 如果指定的容量小于初始容量8，则执行一下if中的逻辑操作 if (numElements &gt;= initialCapacity) &#123; initialCapacity = numElements; initialCapacity |= (initialCapacity &gt;&gt;&gt; 1); initialCapacity |= (initialCapacity &gt;&gt;&gt; 2); initialCapacity |= (initialCapacity &gt;&gt;&gt; 4); initialCapacity |= (initialCapacity &gt;&gt;&gt; 8); initialCapacity |= (initialCapacity &gt;&gt;&gt; 16); initialCapacity++; if (initialCapacity &lt; 0) // Too many elements, must back off initialCapacity &gt;&gt;&gt;= 1; // Good luck allocating 2 ^ 30 elements &#125; elements = (E[]) new Object[initialCapacity]; &#125; 此方法是给数组分配初始容量，初始容量并不是numElements，而是大于指定长度的最小的2的幂正数所以ArrayDeque的容量一定是2的幂整数.至于这是为什么，应该是计算机内存分配的关系吧。2的幂次方页空间分配的更快。（个人猜测） 重要方法入队（添加元素到队尾）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 /** * 增加一个元素，如果队列已满，则抛出一个IIIegaISlabEepeplian异常 */ public boolean add(E e) &#123; // 调用addLast方法，将元素添加到队尾 addLast(e); return true; &#125; * 把元素填入到队列前端.即在head的前面添加元素 */ public void addFirst(E e) &#123; if (e == null) //允许插入空值 throw new NullPointerException(); elements[head = (head - 1) &amp; (elements.length - 1)] = e; if (head == tail) //表示队列已经满了 doubleCapacity(); //扩充容量&#125; /** * 将元素添加到队尾 */ public void addLast(E e) &#123; // 如果元素为null，咋抛出空指针异常 if (e == null) throw new NullPointerException(); // 将元素e放到数组的tail位置 elements[tail] = e; // 判断tail和head是否相等，如果相等则对数组进行扩容 if ( (tail = (tail + 1) &amp; ( elements.length - 1)) == head) // 进行两倍扩容 doubleCapacity(); &#125; /** * 添加一个元素 */ public boolean offer(E e) &#123; // 调用offerLast方法，将元素添加到队尾 return offerLast(e); &#125; /** * Inserts the specified element at the front of this deque. */ public boolean offerFirst(E e) &#123; addFirst(e); return true; &#125; /** * 在队尾添加一个元素 */ public boolean offerLast(E e) &#123; // 调用addLast方法，将元素添加到队尾 addLast(e); return true; &#125; addFirst()addFirst(E e)的作用是在Deque的首端插入元素，也就是在head的前面插入元素，在空间足够且下标没有越界的情况下，只需要将elements[–head] = e即可。实际需要考虑：1.空间是否够用 2.下标是否越界的问题。上图中，如果head为0之后接着调用addFirst()，虽然空余空间还够用，但head为-1，下标越界了。下列代码很好的解决了这两个问题. 123456789* 把元素填入到队列前端.即在head的前面添加元素 */ public void addFirst(E e) &#123; if (e == null) //允许插入空值 throw new NullPointerException(); elements[head = (head - 1) &amp; (elements.length - 1)] = e; if (head == tail) //表示队列已经满了 doubleCapacity(); //扩充容量&#125; 上述代码我们看到，空间问题是在插入之后解决的，因为tail总是指向下一个可插入的空位，也就意味着elements数组至少有一个空位，所以插入元素的时候不用考虑空间问题。下标越界的处理解决起来非常简单，head = (head - 1) &amp; (elements.length - 1)就可以了，这段代码相当于取余，同时解决了head为负值的情况。因为elements.length必需是2的指数倍，elements - 1就是二进制低位全1，跟head - 1相与之后就起到了取模的作用，如果head - 1为负数（其实只可能是-1），则相当于对其取相对于elements.length的补码。比如说，如果elements.length为8，则(elements.length - 1)为7，二进制为0111，对于负数-1，与7相与，结果为7，对于正数8，与7相与，结果为0，都能达到循环数组中找下一个正确位置的目的。对于取与操作而言，有下面的结论：12345678记mod = elements.length = 2^k, a为[-1,module+1]之间的一个整数，那么有： a == -1: a &amp; (mod-1) == mod - 1; 0 &lt;= a &lt; mod: a &amp; (mod - 1) == a a == mod: a &amp; (mod - 1) == 0 下面再说说扩容函数doubleCapacity()，其逻辑是申请一个更大的数组（原数组的两倍），然后将原数组复制过去。过程如下图所示： 图中我们看到，复制分两次进行，第一次复制head右边的元素，第二次复制head左边的元素。 123456789101112131415161718 /** 将队列的容量变成二倍 * Doubles the capacity of this deque. Call only when full, i.e., * when head and tail have wrapped around to become equal. */ private void doubleCapacity() &#123; assert head == tail; int p = head; int n = elements.length; int r = n - p; // number of elements to the right of p int newCapacity = n &lt;&lt; 1; if (newCapacity &lt; 0) throw new IllegalStateException("Sorry, deque too big"); Object[] a = new Object[newCapacity]; System.arraycopy(elements, p, a, 0, r); System.arraycopy(elements, 0, a, r, p); elements = a; head = 0; tail = n; addLast()addLast(E e)的作用是在Deque的尾端插入元素，也就是在tail的位置插入元素，由于tail总是指向下一个可以插入的空位，因此只需要elements[tail] = e;即可。插入完成后再检查空间，如果空间已经用光，则调用doubleCapacity()进行扩容。 12345678910 /** * Inserts the specified element at the end of this deque. */ public void addLast(E e) &#123; if (e == null) throw new NullPointerException(); elements[tail] = e; if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head) //在tail位置后面加入元素 doubleCapacity(); &#125; 下标越界处理方式和addFirst()相同 offerFirst(),offerLast()这两个方法从源码看的很清楚，与addxx()方法的区别就是:add()方法插入失败(插入一个null)会抛出异常，而offer()方法至于插入成功时才会返回true，可用于某些判断。 出队（移除并返回队头元素）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 /** * 移除并返回队列头部的元素，如果队列为空，则抛出一个NoSuchElementException异常 */ public E remove() &#123; // 调用removeFirst方法，移除队头的元素 return removeFirst(); &#125; /** * @throws NoSuchElementException &#123;@inheritDoc&#125; */ public E removeFirst() &#123; // 调用pollFirst方法，移除并返回队头的元素 E x = pollFirst(); // 如果队列为空，则抛出NoSuchElementException异常 if (x == null) throw new NoSuchElementException(); return x; &#125; /** * @throws NoSuchElementException &#123;@inheritDoc&#125; */ public E removeLast() &#123; E x = pollLast(); if (x == null) throw new NoSuchElementException(); return x; &#125; /** * 移除并返问队列头部的元素，如果队列为空，则返回null */ public E poll() &#123; // 调用pollFirst方法，移除并返回队头的元素 return pollFirst(); &#125; public E pollFirst() &#123; int h = head ; // 取出数组队头位置的元素 E result = elements[h]; // Element is null if deque empty // 如果数组队头位置没有元素，则返回null值 if (result == null) return null; // 将数组队头位置置空，也就是删除元素 elements[h] = null; // Must null out slot // 将head指针往前移动一个位置 head = (h + 1) &amp; (elements .length - 1); // 将队头元素返回 return result; &#125; public E pollLast() &#123; int t = (tail - 1) &amp; (elements.length - 1); //因为tail总是指向下一个队列元素，所以pollLast时候，实际取得是tail-1位置的元素 @SuppressWarnings("unchecked") E result = (E) elements[t]; if (result == null) //null值意味着deque为空 return null; elements[t] = null; tail = t; return result; &#125; 可以看到，remove方法和poll方法的区别是：如果没有出队元素(null)，remove方法抛出异常，而poll方法返回null; 返回队列元素(不出队)123456789101112131415161718192021222324252627282930313233343536373839404142434445 /** * 返回队列头部的元素，如果队列为空，则抛出一个NoSuchElementException异常 */ public E element() &#123; // 调用getFirst方法，获取队头的元素 return getFirst(); &#125; /** * @throws NoSuchElementException &#123;@inheritDoc&#125; . */ public E getFirst() &#123; // 取得数组head位置的元素 E x = elements[head ]; // 如果数组head位置的元素为null，则抛出异常 if (x == null) throw new NoSuchElementException(); return x; &#125; /** * @throws NoSuchElementException &#123;@inheritDoc&#125; */ public E getLast() &#123; @SuppressWarnings("unchecked") E result = (E) elements[(tail - 1) &amp; (elements.length - 1)]; if (result == null) throw new NoSuchElementException(); return result; &#125; /** * 返回队列头部的元素，如果队列为空，则返回null . */ public E peek() &#123; // 调用peekFirst方法，获取队头的元素 return peekFirst(); &#125; public E peekFirst() &#123; // 取得数组head位置的元素并返回 return elements [head]; // elements[head] is null if deque empty &#125; public E peekLast() &#123; return (E) elements[(tail - 1) &amp; (elements.length - 1)]; &#125; get()和peek()方法的区别在于：get()方法取到的元素是null(队列为空)时，抛出异常，而peek()方法返回null; push(),pop()显而易见的操作，把ArrayDeque当做堆栈使用时，push()即为在head处插入元素，pop（）即为删除head处元素。 1234567public void push(E e) &#123; addFirst(e); &#125; public E pop() &#123; return removeFirst(); &#125; 其他12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 /** * Returns the number of elements in this deque. */ public int size() &#123; return (tail - head) &amp; (elements.length - 1); &#125; /** * Returns an array containing all of the elements in this deque * in proper sequence (from first to last element). */ public Object[] toArray() &#123; return copyElements(new Object[size()]); &#125; public void clear() &#123;//清空操作 int h = head; int t = tail; if (h != t) &#123; // head != tail 表示队列元素 不为空 head = tail = 0;//设置head 和 tail 初始状态 int i = h; int mask = elements.length - 1; do &#123; elements[i] = null;//配合循环将所有元素设置为null i = (i + 1) &amp; mask; &#125; while (i != t); &#125; &#125; //遍历集合，正向遍历,从head -- tailpublic Iterator&lt;E&gt; iterator() &#123; return new DeqIterator(); &#125; //反向遍历public Iterator&lt;E&gt; descendingIterator() &#123; return new DescendingIterator(); &#125; public boolean contains(Object o) &#123;//判断队列是否包含该元素 if (o == null) return false; int mask = elements.length - 1; int i = head; E x; while ( (x = elements[i]) != null) &#123;//从head元素向后猪哥判断,是否equals if (o.equals(x)) return true; i = (i + 1) &amp; mask; &#125; return false; &#125; public int size() &#123;//获取队列元素个数,(tail - head) &amp; (elements.length - 1)保证大小在有效范围内。 return (tail - head) &amp; (elements.length - 1); &#125; public boolean isEmpty() &#123;//入队操作,tail+=1;出队操作head+=1;当一直出队元素的时候,head一直+，会==tail,此时head==tail都指向null元素。 return head == tail; &#125;]]></content>
      <categories>
        <category>java源码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ArrayDeque</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC使用@ResponseBody返回json 中文乱码]]></title>
    <url>%2F2017%2F08%2F10%2FSpringMVC-%E4%BD%BF%E7%94%A8-ResponseBody%E8%BF%94%E5%9B%9Ejson-%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Spring中解析字符串的转换器默认编码居然是ISO-8859-1,如何处理utf-8中文字符下面这都两个可以方法一，使用（produces = “application/json; charset=utf-8”）：123@RequestMapping(value="/getUsersByPage",produces = "application/json; charset=utf-8")@ResponseBodypublic String getUsersByPage(String page,String rows,String text,HttpServletRequest request,HttpServletResponse response)&#123; 方法二，在spring-mvc.xml中添加：123456789101112&lt;!-- 处理请求返回json字符串的中文乱码问题 --&gt; &lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"&gt; &lt;property name="supportedMediaTypes"&gt; &lt;list&gt; &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; 以上两种方式经过验证都没有问题。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC 使用HandlerMethodArgumentResolver自定义解析器实现请求数据绑定方法入参]]></title>
    <url>%2F2017%2F08%2F07%2FSpringMVC%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8%E5%AE%9E%E7%8E%B0%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[问题首先，我们遇到的问题是，当我们需要在controller中频繁的从session中获取数据，比如向下面这样在controller中需要从session中获取user对象，那么可能你会想到在controller里面或者其他类里面写这样的代码，然后在controller里面调用….1234public User getLoginUser(HttpServletRequest request) &#123; HttpSession session = request.getSession(); return (User) session.getAttribute("user"); &#125; 总感觉特别的不好…现在如果我们看了下面介绍的HandlerMethodArgumentResolver自定义解析器实现的请求数据绑定方法入参，你就会看到像下面的代码只需要一个注解就能解决上面的问题↓12345@RequestMapping("/index") public String index(@MyUser User user,ModelMap modelMap)&#123; logger.info(user.getUsername()+"---------------------------"); return "login"; &#125; 用HandlerMethodArgumentResolver解决首先，我们需要知道一点的就是SpringMVC的工作流程，SpringMVC的DispatchServlet会根据请求来找到对应的HandlerMapping，最终spring会选择用RequestMappingHandlerMapping，然后根据RequestMappingHandlerMapping来获取HandlerMethod，然后来找支持的HandlerMethodArgumentResolver来处理对应controller的方法的入参。首先，我们需要做的就是创建一个Annotation123456@Target(ElementType.PARAMETER) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface MyUser &#123; String value() default ""; &#125; 然后我们要做的就是创建一个MyUserMethodArgumentResolver这个类来实现HandlerMethodArgumentResolver这个接口123456789101112131415161718192021222324252627282930 public class MyUserMethodArgumentResolver implements HandlerMethodArgumentResolver &#123; @Override public boolean supportsParameter(MethodParameter methodParameter) &#123; return methodParameter.hasParameterAnnotation(ManyUser.class); &#125; @Override public Object resolveArgument(MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest nativeWebRequest, WebDataBinderFactory webDataBinderFactory) throws Exception &#123; 8. //直接返回request域对象的user9. return nativeWebRequest.getAttribute("user", NativeWebRequest.SCOPE_REQUEST);; 10. //或者这里你也可以直接返回自己创建的User对象 11. /* 12. User user = new User(); 13. user.setUsername("yangpeng"); 14. return user; 15. */ 16. /**自定义实现，比如参数是很多用户：如 custom?names=lyncc,fly,ted&amp;ids=1,2,317. List&lt;User&gt; users = new ArrayList&lt;User&gt;(); 18. String names = (String)webRequest.getParameter("names"); 19. String ids = (String)webRequest.getParameter("ids"); 20. if(null != names &amp;&amp; null != ids)&#123; 21. String[] nameStrs = names.trim().split(","); 22. String[] idStrs = ids.trim().split(","); 23. for(int i = 0;i&lt;nameStrs.length;i++)&#123; 24. User user = new User(Integer.parseInt(idStrs[i]), nameStrs[i]);25. users.add(user); 26. &#125; 27. &#125; 28. return users; //返回list 例如注解式 @manyUser List&lt;User&gt; users29. &#125; 30. &#125; &#125; Spring默认会注册多个HandlerMethodArgumentResolver来处理不同的请求，Spring会根据HandlerMethodArgumentResolver的supportsParameter()方法来判断是否支持处理当前请求。第一个supportsParameter方法是判断这个MyUserMethodArgumentResolver是否支持传入的MethodParameter对象。第二个resolveArgument方法是处理具体的需要绑定到方法入参，返回的对象就是需要绑定的对象，这里我是直接从session里面获取了一个user的对象直接返回，或者你也可以在这里直接创建一个User对象然后返回用于测试是一样的。接下来就是在spring-mvc.xml中配置了 &lt;mvc:annotation-driven&gt; &lt;mvc:argument-resolvers&gt; &lt;bean class="com.yp.code.common.bind.method.MyUserMethodArgumentResolver"&gt;&lt;/bean&gt; &lt;/mvc:argument-resolvers&gt; &lt;/mvc:annotation-driven&gt; 最后就是使用创建的@MyUser这个Annotation来让SpringMVC自动的帮你绑定到Controller的方法里面了 @RequestMapping("/index") public String index(@MyUser User user,ModelMap modelMap){ System.out.println(user.getUsername()); return "login"; } 这样就非常优雅的解决了上面的问题。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
        <tag>自定义参数解析器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用@ExceptionHandler，@ControllerAdvice 来进行异常处理]]></title>
    <url>%2F2017%2F08%2F05%2F%E7%94%A8-ExceptionHandler%EF%BC%8C-ControllerAdvice-%E6%9D%A5%E8%BF%9B%E8%A1%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[有时候我们想统一处理一个Controller中抛出的异常怎么搞呢？直接在Controller里面加上用@ExceptionHandler标注一个处理异常的方法像下面这样子，@ExceptionHandler只在当前controller里面有效。当前controller中所有抛出指定异常的方法。123456789101112131415161718192021222324252627282930313233343536371. @ExceptionHandler(MissingServletRequestParameterException.class) 2. @ResponseStatus(HttpStatus.BAD_REQUEST) 3. public void processMethod(MissingServletRequestParameterException ex,HttpServletRequest request ,HttpServletResponse response) throws IOException &#123; 4. System.out.println("抛异常了！"+ex.getLocalizedMessage()); 5. logger.error("抛异常了！"+ex.getLocalizedMessage()); 6. response.getWriter().printf(ex.getMessage()); 7. response.flushBuffer(); ``` 这样，Controller里面的方法抛出了MissingServletRequestParameterException异常就会执行上面的这个方法来进行异常处理。像我下面的代码````java1. @RequestMapping("/index") 2. public String index(@RequestParam String id,ModelMap modelMap)&#123; 3. if (id==null)&#123;4. throw new MissingServletRequestParameterException();5. &#125;6. return "login"; 7. &#125; ``` 如果我没有传入id值，那么就会抛出MissingServletRequestParameterException的异常，就会被上面的异常处理方法处理。上面的@ExceptionHandler(MissingServletRequestParameterException.class)这个注解的value的值是一个Class[]类型的，这里的ExceptionClass是你自己指定的，你也可以指定多个需要处理的异常类型，比如这样@ExceptionHandler(value = &#123;MissingServletRequestParameterException.class,BindException.class&#125;)，这样就会处理多个异常了。另一种更加通用的方法时：首先定义这样一个统一异常处理类```javaExceptionController.Java1. import net.sf.json.JSONObject; 2. public abstract class ExceptionController &#123; 3. @ExceptionHandler 4. public @ResponseBody String exceptionProcess(HttpServletRequest request, HttpServletResponse 5. response, RuntimeException ex) &#123; 6. JSONObject json = new JSONObject(); 7. json.put("isError", true); 8. json.put("msg", ex.getMessage()); 9. return json.toString(); 10. &#125; 11. &#125; 在需要进行统一处理的类中继承这个class 1. import net.sf.json.JSONObject; 2. @RequestMapping("/auth/customer") 3. @Controller 4. @LoginAuth 5. public class CustomerController extends ExceptionController { 6. @Resource 7. private CustomerService customerService; 8. 9. /** 10. * 11. * @param page 第几页，从1开始 12. * @param rows 每页多少记录的行数 13. * @return JSON String 14. */ 15. @RequestMapping("/querybypage") 16. @ResponseBody 17. public String QueryByPage(int page, int rows) { 18. //当为缺省值的时候进行赋值 19. int currentpage = ( page == 0) ? 1: page; //第几页 20. int pageSize = (rows == 0) ? 5: rows; //每页显示数量 21. int index = (currentpage - 1) * pageSize; //从第几条开始显示 22. JSONObject map = customerService.queryByPage(index, pageSize); 23. return map.toString(); 24. } 25. 26. @RequestMapping("/test") 27. public @ResponseBody Object test() { 28. JSONObject json = new JSONObject(); 29. json.put("status", "success"); 30. String str = null; 31. str.toString(); 32. return json.toString(); 33. } 34. } 其中重要的一行是 public class CustomerController extends ExceptionController这样CustomController里的方法被访问的时候， 如果有异常，就会被exceptionProces()处理.因为继承之后，子类中都有这个标注的方法了。但这个注解只会是在当前的Controller里面起作用，如果想在所有的Controller里面统一处理异常的话，可以用@ControllerAdvice来创建一个专门处理全局的的类。`java @ControllerAdvice public class SpringExceptionHandler{ /** 全局处理Exception 错误的情况下返回500 @param ex @param req @return */ @ExceptionHandler(value = {Exception.class}) public ResponseEntity handleOtherExceptions(final Exception ex, final WebRequest req) { TResult tResult = new TResult(); //处理结果 tResult.setStatus(CodeType.V_500); tResult.setErrorMessage(ex.getMessage()); return new ResponseEntity(tResult,HttpStatus.OK); } }`注意，这种注解在springmvc的配置文件中扫描是，要把@ControllerAdvice也包含进来，否则不起作用。此外，@ControllerAdvice还可以用于全局的requestMapping，较少用。参考：http://jinnianshilongnian.iteye.com/blog/1866350http://blog.csdn.net/u013632755/article/details/49908621]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
        <tag>异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC自定义注解和拦截器实现用户行为验证]]></title>
    <url>%2F2017%2F08%2F01%2FSpringMVC%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[最近在进行项目开发的时候需要对接口做Session验证 自定义一个注解@AuthCheckAnnotation1234567@Documented@Target(ElementType.METHOD)@Inherited@Retention(RetentionPolicy.RUNTIME)public @interface AuthCheckAnnotation &#123; boolean check() default false;//默认不需要进行验证&#125; 定义一个相应的拦截器，在springMVC配置文件中进行配置拦截器：&emsp;spring为我们提供了org.springframework.web.servlet.handler.HandlerInterceptorAdapter这个适配器，继承此类，可以非常方便的实现自己的拦截器。可以根据我们的需要重写preHandle、postHandle、afterCompletio方法。分别实现预处理、后处理（调用了Service并返回ModelAndView，但未进行页面渲染）、返回处理（已经渲染了页面） 在preHandle中，可以进行编码、安全控制等处理； 在postHandle中，有机会修改ModelAndView； 在afterCompletion中，可以根据ex是否为null判断是否发生了异常，进行日志记录。123456789101112131415161718192021222324public class AuthCheckInteceptor extends HandlerInterceptorAdapter &#123; @Autowired UserInfoService userInfoService ; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; HandlerMethod methodHandler=(HandlerMethod) handler; AuthCheckAnnotation auth=methodHandler.getMethodAnnotation(AuthCheckAnnotation.class); //如果方法中添加了@AuthCheckAnnotation 这里的auth不为null //如果@AuthCheckAnnotation(check=false) 这里的auth为false,即不用进行拦截验证，@AuthCheckAnnotation默认为前面定义的true if(auth!=null&amp;&amp;!auth.check())&#123; return true; &#125; UserInfo user=(UserInfo)request.getSession().getAttribute(Constants.SESSION_USER); try &#123; userInfoService.login(request, user); return true; &#125; catch (Exception e) &#123; request.getRequestDispatcher("login.do").forward(request, response); return false; &#125; &#125;&#125; 在springMVC.xml文件中添加拦截器123456&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/*.do" /&gt; &lt;bean class="com.party.common.interceptor.AuthCheckInteceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 在springMVC controller中使用实例1234567@AuthCheckAnnotation(check=true)@RequestMapping("doLogin")@ResponseBodypublic Object doLogin(HttpServletRequest request,HttpServletResponse response)&#123; ....... return RetMessage.toJson(responseBody);&#125; 转：https://www.bbsmax.com/A/QV5Z1jwbJy/]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
        <tag>自定义注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven项目创建时出错]]></title>
    <url>%2F2017%2F07%2F22%2Fmaven%2F</url>
    <content type="text"><![CDATA[哎，一些问题每次出错都要重新找方法解决。以后还是都记录下来把。 问题描述Eclipse创建Maven项目时，报错Could not calculate build plan: Plugin org.apache.maven.plugins:maven-resources-plugin:2.6 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.apache.maven.plugins:maven-resources-plugin:jar:2.6Plugin org.apache.maven.plugins:maven-resources-plugin:2.6 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.apache.maven.plugins:maven-resources-plugin:jar:2.6 解决方案删除本地Maven仓库org.apache.maven.plugins:maven-resources-plugin所在目录文件夹。然后在一个maven项目中的pom.xml文件中增加以下依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt;&lt;/dependency&gt; 然后执行maven install重新下载maven-resources-plugin这个jar包即可。同样的，有可能其他plugin会报类似的错误，解决方法和上面类似。]]></content>
      <categories>
        <category>奇怪的问题</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Xgboost参数]]></title>
    <url>%2F2017%2F06%2F12%2FXgboost%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[XGBoost的参数XGBoost的作者把所有的参数分成了三类： 通用参数：宏观函数控制。 Booster参数：控制每一步的booster(tree/regression)。 学习目标参数：控制训练目标的表现。在这里我会类比GBM来讲解，所以作为一种基础知识，强烈推荐先阅读这篇文章。 通用参数这些参数用来控制XGBoost的宏观功能。booster[默认gbtree]选择每次迭代的模型，有两种选择：gbtree：基于树的模型gbliner：线性模型silent[默认0]当这个参数值为1时，静默模式开启，不会输出任何信息。一般这个参数就保持默认的0，因为这样能帮我们更好地理解模型。nthread[默认值为最大可能的线程数]这个参数用来进行多线程控制，应当输入系统的核数。如果你希望使用CPU全部的核，那就不要输入这个参数，算法会自动检测它。还有两个参数，XGBoost会自动设置，目前你不用管它。接下来咱们一起看booster参数。booster参数尽管有两种booster可供选择，我这里只介绍tree booster，因为它的表现远远胜过linear booster，所以linear booster很少用到。eta[默认0.3]和GBM中的 learning rate 参数类似。通过减少每一步的权重，可以提高模型的鲁棒性。典型值为0.01-0.2。min_child_weight[默认1]决定最小叶子节点样本权重和。和GBM的 min_child_leaf 参数类似，但不完全一样。XGBoost的这个参数是最小样本权重的和，而GBM参数是最小样本总数。这个参数用于避免过拟合。当它的值较大时，可以避免模型学习到局部的特殊样本。但是如果这个值过高，会导致欠拟合。这个参数需要使用CV来调整。max_depth[默认6]和GBM中的参数相同，这个值为树的最大深度。这个值也是用来避免过拟合的。max_depth越大，模型会学到更具体更局部的样本。需要使用CV函数来进行调优。典型值：3-10max_leaf_nodes树上最大的节点或叶子的数量。可以替代max_depth的作用。因为如果生成的是二叉树，一个深度为n的树最多生成n2个叶子。如果定义了这个参数，GBM会忽略max_depth参数。gamma[默认0]在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma指定了节点分裂所需的最小损失函数下降值。这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。max_delta_step[默认0]这参数限制每棵树权重改变的最大步长。如果这个参数的值为0，那就意味着没有约束。如果它被赋予了某个正值，那么它会让这个算法更加保守。通常，这个参数不需要设置。但是当各类别的样本十分不平衡时，它对逻辑回归是很有帮助的。这个参数一般用不到，但是你可以挖掘出来它更多的用处。subsample[默认1]和GBM中的subsample参数一模一样。这个参数控制对于每棵树，随机采样的比例。减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。典型值：0.5-1colsample_bytree[默认1]和GBM里面的max_features参数类似。用来控制每棵随机采样的列数的占比(每一列是一个特征)。典型值：0.5-1colsample_bylevel[默认1]用来控制树的每一级的每一次分裂，对列数的采样的占比。我个人一般不太用这个参数，因为subsample参数和colsample_bytree参数可以起到相同的作用。但是如果感兴趣，可以挖掘这个参数更多的用处。lambda[默认1]权重的L2正则化项。(和Ridge regression类似)。这个参数是用来控制XGBoost的正则化部分的。虽然大部分数据科学家很少用到这个参数，但是这个参数在减少过拟合上还是可以挖掘出更多用处的。alpha[默认1]权重的L1正则化项。(和Lasso regression类似)。可以应用在很高维度的情况下，使得算法的速度更快。scale_pos_weight[默认1]在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。学习目标参数这个参数用来控制理想的优化目标和每一步结果的度量方法。objective[默认reg:linear]这个参数定义需要被最小化的损失函数。最常用的值有： binary:logistic 二分类的逻辑回归，返回预测的概率(不是类别)。 multi:softmax 使用softmax的多分类器，返回预测的类别(不是概率)。在这种情况下，你还需要多设一个参数：num_class(类别数目)。 multi:softprob 和multi:softmax参数一样，但是返回的是每个数据属于各个类别的概率。eval_metric[默认值取决于objective参数的取值]对于有效数据的度量方法。对于回归问题，默认值是rmse，对于分类问题，默认值是error。典型值有： rmse 均方根误差(∑Ni=1ϵ2N−−−−−−√) mae 平均绝对误差(∑Ni=1|ϵ|N) logloss 负对数似然函数值 error 二分类错误率(阈值为0.5) merror 多分类错误率 mlogloss 多分类logloss损失函数 auc 曲线下面积seed(默认0)随机数的种子设置它可以复现随机数据的结果，也可以用于调整参数如果你之前用的是Scikit-learn,你可能不太熟悉这些参数。但是有个好消息，python的XGBoost模块有一个sklearn包，XGBClassifier。这个包中的参数是按sklearn风格命名的。会改变的函数名是：1、eta -&gt; learning_rate2、lambda -&gt; reg_lambda3、alpha -&gt; reg_alpha你肯定在疑惑为啥咱们没有介绍和GBM中的n_estimators类似的参数。XGBClassifier中确实有一个类似的参数，但是，是在标准XGBoost实现中调用拟合函数时，把它作为num_boosting_rounds参数传入。XGBoost Guide 的一些部分是我强烈推荐大家阅读的，通过它可以对代码和参数有一个更好的了解：http://xgboost.readthedocs.io/en/latest/parameter.html#general-parametershttps://github.com/dmlc/xgboost/tree/master/demo/guide-pythonhttp://xgboost.readthedocs.io/en/latest/python/python_api.html本文参考：http://blog.csdn.net/han_xiaoyang/article/details/52665396]]></content>
      <categories>
        <category>Xgboost</category>
      </categories>
      <tags>
        <tag>Xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python求list的平均数、众数、最大值、最小值、极值、方差等]]></title>
    <url>%2F2017%2F06%2F07%2Fpython%E6%B1%82list%E7%9A%84%E5%B9%B3%E5%9D%87%E6%95%B0%E3%80%81%E4%BC%97%E6%95%B0%E3%80%81%E6%9C%80%E5%A4%A7%E5%80%BC%E3%80%81%E6%9C%80%E5%B0%8F%E5%80%BC%E3%80%81%E6%9E%81%E5%80%BC%E3%80%81%E6%96%B9%E5%B7%AE%E7%AD%89%2F</url>
    <content type="text"><![CDATA[数据挖掘中经常会用到一组数据(list)的相关特征。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455'''feature.py'''#最大数def Get_Max(list): return max(list)#最小数def Get_Min(list): return min(list)#极差def Get_Range(list): return max(list) - min(list)#中位数def get_median(data): data = sorted(data) size = len(data) if size % 2 == 0: # 判断列表长度为偶数 median = (data[size//2]+data[size//2-1])/2 if size % 2 == 1: # 判断列表长度为奇数 median = data[(size-1)//2] return median#众数(返回多个众数的平均值)def Get_Most(list): most=[] item_num = dict((item, list.count(item)) for item in list) for k,v in item_num.items(): if v == max(item_num.values()): most.append(k) return sum(most)/len(most)#获取平均数def Get_Average(list): sum = 0 for item in list: sum += item return sum/len(list)#获取方差def Get_Variance(list): sum = 0 average = Get_Average(list) for item in list: sum += (item - average)**2 return sum/len(list)#获取n阶原点距def Get_NMoment(list,n): sum=0 for item in list: sum += item**n return sum/len(list)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用sklearn优雅地进行数据挖掘]]></title>
    <url>%2F2017%2F06%2F07%2F%E4%BD%BF%E7%94%A8sklearn%E4%BC%98%E9%9B%85%E5%9C%B0%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F</url>
    <content type="text"><![CDATA[今天找资料的时候，发现一个很牛的大神。写的博客是真的好。慢慢的汲取养分。转自：http://www.cnblogs.com/jasonfreak/p/5448462.html 使用sklearn进行数据挖掘数据挖掘的步骤数据挖掘通常包括数据采集，数据分析，特征工程，训练模型，模型评估等步骤。使用sklearn工具可以方便地进行特征工程和模型训练工作，在《使用sklearn做单机特征工程》中，我们最后留下了一些疑问：特征处理类都有三个方法fit、transform和fit_transform，fit方法居然和模型训练方法fit同名（不光同名，参数列表都一样），这难道都是巧合？显然，这不是巧合，这正是sklearn的设计风格。我们能够更加优雅地使用sklearn进行特征工程和模型训练工作。此时，不妨从一个基本的数据挖掘场景入手：我们使用sklearn进行虚线框内的工作（sklearn也可以进行文本特征提取）。通过分析sklearn源码，我们可以看到除训练，预测和评估以外，处理其他工作的类都实现了3个方法：fit、transform和fit_transform。从命名中可以看到，fit_transform方法是先调用fit然后调用transform，我们只需要关注fit方法和transform方法即可。 transform方法主要用来对特征进行转换。从可利用信息的角度来说，转换分为无信息转换和有信息转换。无信息转换是指不利用任何其他信息进行转换，比如指数、对数函数转换等。有信息转换从是否利用目标值向量又可分为无监督转换和有监督转换。无监督转换指只利用特征的统计信息的转换，统计信息包括均值、标准差、边界等等，比如标准化、PCA法降维等。有监督转换指既利用了特征信息又利用了目标值信息的转换，比如通过模型选择特征、LDA法降维等。通过总结常用的转换类，我们得到下表：不难看到，只有有信息的转换类的fit方法才实际有用，显然fit方法的主要工作是获取特征信息和目标值信息，在这点上，fit方法和模型训练时的fit方法就能够联系在一起了：都是通过分析特征和目标值，提取有价值的信息，对于转换类来说是某些统计量，对于模型来说可能是特征的权值系数等。另外，只有有监督的转换类的fit和transform方法才需要特征和目标值两个参数。fit方法无用不代表其没实现，而是除合法性校验以外，其并没有对特征和目标值进行任何处理，Normalizer的fit方法实现如下：12345671 def fit(self, X, y=None):2 """Do nothing and return the estimator unchanged3 This method is just there to implement the usual API and hence4 work in pipelines.5 """6 X = check_array(X, accept_sparse='csr')7 return self 基于这些特征处理工作都有共同的方法，那么试想可不可以将他们组合在一起？在本文假设的场景中，我们可以看到这些工作的组合形式有两种：流水线式和并行式。基于流水线组合的工作需要依次进行，前一个工作的输出是后一个工作的输入；基于并行式的工作可以同时进行，其使用同样的输入，所有工作完成后将各自的输出合并之后输出。sklearn提供了包pipeline来完成流水线式和并行式的工作。 数据初貌在此，我们仍然使用IRIS数据集来进行说明。为了适应提出的场景，对原数据集需要稍微加工：1234567891011 1 from numpy import hstack, vstack, array, median, nan 2 from numpy.random import choice 3 from sklearn.datasets import load_iris 4 5 #特征矩阵加工 6 #使用vstack增加一行含缺失值的样本(nan, nan, nan, nan) 7 #使用hstack增加一列表示花的颜色（0-白、1-黄、2-红），花的颜色是随机的，意味着颜色并不影响花的分类 8 iris.data = hstack((choice([0, 1, 2], size=iris.data.shape[0]+1).reshape(-1,1), vstack((iris.data, array([nan, nan, nan, nan]).reshape(1,-1))))) 9 #目标值向量加工10 #增加一个目标值，对应含缺失值的样本，值为众数11 iris.target = hstack((iris.target, array([median(iris.target)]))) 关键技术并行处理，流水线处理，自动化调参，持久化是使用sklearn优雅地进行数据挖掘的核心。并行处理和流水线处理将多个特征处理工作，甚至包括模型训练工作组合成一个工作（从代码的角度来说，即将多个对象组合成了一个对象）。在组合的前提下，自动化调参技术帮我们省去了人工调参的反锁。训练好的模型是贮存在内存中的数据，持久化能够将这些数据保存在文件系统中，之后使用时无需再进行训练，直接从文件系统中加载即可。并行处理并行处理使得多个特征处理工作能够并行地进行。根据对特征矩阵的读取方式不同，可分为整体并行处理和部分并行处理。整体并行处理，即并行处理的每个工作的输入都是特征矩阵的整体；部分并行处理，即可定义每个工作需要输入的特征矩阵的列。 整体并行处理pipeline包提供了FeatureUnion类来进行整体并行处理：12345678910111213 1 from numpy import log1p 2 from sklearn.preprocessing import FunctionTransformer 3 from sklearn.preprocessing import Binarizer 4 from sklearn.pipeline import FeatureUnion 5 6 #新建将整体特征矩阵进行对数函数转换的对象 7 step2_1 = ('ToLog', FunctionTransformer(log1p)) 8 #新建将整体特征矩阵进行二值化类的对象 9 step2_2 = ('ToBinary', Binarizer())10 #新建整体并行处理对象11 #该对象也有fit和transform方法，fit和transform方法均是并行地调用需要并行处理的对象的fit和transform方法12 #参数transformer_list为需要并行处理的对象列表，该列表为二元组列表，第一元为对象的名称，第二元为对象13 step2 = ('FeatureUnion', FeatureUnion(transformer_list=[step2_1, step2_2, step2_3])) 部分并行处理整体并行处理有其缺陷，在一些场景下，我们只需要对特征矩阵的某些列进行转换，而不是所有列。pipeline并没有提供相应的类（仅OneHotEncoder类实现了该功能），需要我们在FeatureUnion的基础上进行优化：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 1 from sklearn.pipeline import FeatureUnion, _fit_one_transformer, _fit_transform_one, _transform_one 2 from sklearn.externals.joblib import Parallel, delayed 3 from scipy import sparse 4 import numpy as np 5 6 #部分并行处理，继承FeatureUnion 7 class FeatureUnionExt(FeatureUnion): 8 #相比FeatureUnion，多了idx_list参数，其表示每个并行工作需要读取的特征矩阵的列 9 def __init__(self, transformer_list, idx_list, n_jobs=1, transformer_weights=None):10 self.idx_list = idx_list11 FeatureUnion.__init__(self, transformer_list=map(lambda trans:(trans[0], trans[1]), transformer_list), n_jobs=n_jobs, transformer_weights=transformer_weights)12 13 #由于只部分读取特征矩阵，方法fit需要重构14 def fit(self, X, y=None):15 transformer_idx_list = map(lambda trans, idx:(trans[0], trans[1], idx), self.transformer_list, self.idx_list)16 transformers = Parallel(n_jobs=self.n_jobs)(17 #从特征矩阵中提取部分输入fit方法18 delayed(_fit_one_transformer)(trans, X[:,idx], y)19 for name, trans, idx in transformer_idx_list)20 self._update_transformer_list(transformers)21 return self22 23 #由于只部分读取特征矩阵，方法fit_transform需要重构24 def fit_transform(self, X, y=None, **fit_params):25 transformer_idx_list = map(lambda trans, idx:(trans[0], trans[1], idx), self.transformer_list, self.idx_list)26 result = Parallel(n_jobs=self.n_jobs)(27 #从特征矩阵中提取部分输入fit_transform方法28 delayed(_fit_transform_one)(trans, name, X[:,idx], y,29 self.transformer_weights, **fit_params)30 for name, trans, idx in transformer_idx_list)31 32 Xs, transformers = zip(*result)33 self._update_transformer_list(transformers)34 if any(sparse.issparse(f) for f in Xs):35 Xs = sparse.hstack(Xs).tocsr()36 else:37 Xs = np.hstack(Xs)38 return Xs39 40 #由于只部分读取特征矩阵，方法transform需要重构41 def transform(self, X):42 transformer_idx_list = map(lambda trans, idx:(trans[0], trans[1], idx), self.transformer_list, self.idx_list)43 Xs = Parallel(n_jobs=self.n_jobs)(44 #从特征矩阵中提取部分输入transform方法45 delayed(_transform_one)(trans, name, X[:,idx], self.transformer_weights)46 for name, trans, idx in transformer_idx_list)47 if any(sparse.issparse(f) for f in Xs):48 Xs = sparse.hstack(Xs).tocsr()49 else:50 Xs = np.hstack(Xs)51 return Xs 在本文提出的场景中，我们对特征矩阵的第1列（花的颜色）进行定性特征编码，对第2、3、4列进行对数函数转换，对第5列进行定量特征二值化处理。使用FeatureUnionExt类进行部分并行处理的代码如下：123456789101112131415 1 from numpy import log1p 2 from sklearn.preprocessing import OneHotEncoder 3 from sklearn.preprocessing import FunctionTransformer 4 from sklearn.preprocessing import Binarizer 5 6 #新建将部分特征矩阵进行定性特征编码的对象 7 step2_1 = ('OneHotEncoder', OneHotEncoder(sparse=False)) 8 #新建将部分特征矩阵进行对数函数转换的对象 9 step2_2 = ('ToLog', FunctionTransformer(log1p))10 #新建将部分特征矩阵进行二值化类的对象11 step2_3 = ('ToBinary', Binarizer())12 #新建部分并行处理对象13 #参数transformer_list为需要并行处理的对象列表，该列表为二元组列表，第一元为对象的名称，第二元为对象14 #参数idx_list为相应的需要读取的特征矩阵的列15 step2 = ('FeatureUnionExt', FeatureUnionExt(transformer_list=[step2_1, step2_2, step2_3], idx_list=[[0], [1, 2, 3], [4]])) 流水线处理pipeline包提供了Pipeline类来进行流水线处理。流水线上除最后一个工作以外，其他都要执行fit_transform方法，且上一个工作输出作为下一个工作的输入。最后一个工作必须实现fit方法，输入为上一个工作的输出；但是不限定一定有transform方法，因为流水线的最后一个工作可能是训练！根据本文提出的场景，结合并行处理，构建完整的流水线的代码如下：123456789101112131415161718192021222324252627282930313233 1 from numpy import log1p 2 from sklearn.preprocessing import Imputer 3 from sklearn.preprocessing import OneHotEncoder 4 from sklearn.preprocessing import FunctionTransformer 5 from sklearn.preprocessing import Binarizer 6 from sklearn.preprocessing import MinMaxScaler 7 from sklearn.feature_selection import SelectKBest 8 from sklearn.feature_selection import chi2 9 from sklearn.decomposition import PCA10 from sklearn.linear_model import LogisticRegression11 from sklearn.pipeline import Pipeline12 13 #新建计算缺失值的对象14 step1 = ('Imputer', Imputer())15 #新建将部分特征矩阵进行定性特征编码的对象16 step2_1 = ('OneHotEncoder', OneHotEncoder(sparse=False))17 #新建将部分特征矩阵进行对数函数转换的对象18 step2_2 = ('ToLog', FunctionTransformer(log1p))19 #新建将部分特征矩阵进行二值化类的对象20 step2_3 = ('ToBinary', Binarizer())21 #新建部分并行处理对象，返回值为每个并行工作的输出的合并22 step2 = ('FeatureUnionExt', FeatureUnionExt(transformer_list=[step2_1, step2_2, step2_3], idx_list=[[0], [1, 2, 3], [4]]))23 #新建无量纲化对象24 step3 = ('MinMaxScaler', MinMaxScaler())25 #新建卡方校验选择特征的对象26 step4 = ('SelectKBest', SelectKBest(chi2, k=3))27 #新建PCA降维的对象28 step5 = ('PCA', PCA(n_components=2))29 #新建逻辑回归的对象，其为待训练的模型作为流水线的最后一步30 step6 = ('LogisticRegression', LogisticRegression(penalty='l2'))31 #新建流水线处理对象32 #参数steps为需要流水线处理的对象列表，该列表为二元组列表，第一元为对象的名称，第二元为对象33 pipeline = Pipeline(steps=[step1, step2, step3, step4, step5, step6]) 自动化调参网格搜索为自动化调参的常见技术之一，grid_search包提供了自动化调参的工具，包括GridSearchCV类。对组合好的对象进行训练以及调参的代码如下：123456781 from sklearn.grid_search import GridSearchCV2 3 #新建网格搜索对象4 #第一参数为待训练的模型5 #param_grid为待调参数组成的网格，字典格式，键为参数名称（格式“对象名称__子对象名称__参数名称”），值为可取的参数值列表6 grid_search = GridSearchCV(pipeline, param_grid=&#123;'FeatureUnionExt__ToBinary__threshold':[1.0, 2.0, 3.0, 4.0], 'LogisticRegression__C':[0.1, 0.2, 0.4, 0.8]&#125;)7 #训练以及调参8 grid_search.fit(iris.data, iris.target) 持久化externals.joblib包提供了dump和load方法来持久化和加载内存数据：12345671 #持久化数据2 #第一个参数为内存中的对象3 #第二个参数为保存在文件系统中的名称4 #第三个参数为压缩级别，0为不压缩，3为合适的压缩级别5 dump(grid_search, 'grid_search.dmp', compress=3)6 #从文件系统中加载数据到内存中7 grid_search = load('grid_search.dmp') 回顾注意：组合和持久化都会涉及pickle技术，在sklearn的技术文档中有说明，将lambda定义的函数作为FunctionTransformer的自定义转换函数将不能pickle化。 总结2015年我设计了一个基于sklearn的自动化特征工程的工具，其以Mysql数据库作为原始数据源，提供了“灵活的”特征提取、特征处理的配置方法，同时重新封装了数据、特征和模型，以方便调度系统识别。说灵活，其实也只是通过配置文件的方式定义每个特征的提取和处理的sql语句。但是纯粹使用sql语句来进行特征处理是很勉强的，除去特征提取以外，我又造了一回轮子，原来sklearn提供了这么优秀的特征处理、工作组合等功能。所以，我在这个博客中先不提任何算法和模型，先从数据挖掘工作的第一步开始，使用基于Python的各个工具把大部分步骤都走了一遍（抱歉，我暂时忽略了特征提取），希望这样的梳理能够少让初学者走弯路吧。]]></content>
      <categories>
        <category>sklearn学习</category>
      </categories>
      <tags>
        <tag>数据挖掘</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用sklearn做数据预处理]]></title>
    <url>%2F2017%2F06%2F06%2F%E7%94%A8sklearn%E5%81%9A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[用sklearn做机器学习的时候，一直都是用的时候再去网上找资料，结果每次都要重新找，很麻烦。终于下决心好好总结一下，平时经常用的一些sklearn的东西（或其他相关知识），希望能写成一个系列的笔记。 概要这次就总结下sklearn数据预处理。主要是别人博客的知识，汇总一下。sklearn是一个常用的机器学习库，其中的sklearn.preprocessing模块包含了常用的预处理函数，包括数据的清洗，如缺失值和零值的填充，数据标准化，二值化和哑编码等。 数据预处理1.标准化（均值去除和按方差比例缩放）将数据转化为均值为零，方差为一的数据，形如标准正态分布（高斯分布）。实际操作中，经常忽略特征数据的分布形状，移除每个特征均值，划分离散特征的标准差，从而等级化，进而实现数据中心化。在利用机器学习算法（例如SVM）的过程中，如果目标函数中的一个特征的方差的阶数的量级高于其他特征的方差，那么这一特征就会在目标函数中占主导地位，从而“淹没”其他特征的作用。数据标准化的意义： 消除量纲影响和变量自身变异大小和数值大小的影响。 数据同趋化，主要解决不同性质数据问题，对不同性质指标直接加总不能正确反映不同作用力的综合结果Z-score标准化基于原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。公式为：(X-mean)/std （mean为均值，std为标准差）计算时对每个属性/每列分别进行。将数据按期属性（按列进行）减去其均值，并处以其方差。得到的结果是，对于每个属性/每列来说所有数据都聚集在0附近，方差为1。用sklearn实现有两种方式：1.使用sklearn.preprocessing.scale()函数，可以直接将给定数据进行标准化。123456789101112131415161718&gt;&gt;&gt; from sklearn import preprocessing&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; X = np.array([[ 1., -1., 2.],... [ 2., 0., 0.],... [ 0., 1., -1.]])&gt;&gt;&gt; X_scaled = preprocessing.scale(X) &gt;&gt;&gt; X_scaled array([[ 0. ..., -1.22..., 1.33...], [ 1.22..., 0. ..., -0.26...], [-1.22..., 1.22..., -1.06...]]) &gt;&gt;&gt;#处理后数据的均值和方差&gt;&gt;&gt; X_scaled.mean(axis=0)array([ 0., 0., 0.])#零均值 &gt;&gt;&gt; X_scaled.std(axis=0)array([ 1., 1., 1.])#单位方差 2.使用sklearn.preprocessing.StandardScaler类，使用该类的好处在于可以保存训练集中的参数（均值、方差）直接使用其对象转换测试集数据。12345678910111213141516171819&gt;&gt;&gt; scaler = preprocessing.StandardScaler().fit(X)&gt;&gt;&gt; scalerStandardScaler(copy=True, with_mean=True, with_std=True) &gt;&gt;&gt; scaler.mean_ array([ 1. ..., 0. ..., 0.33...]) &gt;&gt;&gt; scaler.std_ array([ 0.81..., 0.81..., 1.24...]) &gt;&gt;&gt; scaler.transform(X) array([[ 0. ..., -1.22..., 1.33...], [ 1.22..., 0. ..., -0.26...], [-1.22..., 1.22..., -1.06...]]) &gt;&gt;&gt;#可以直接使用训练集对测试集数据进行转换&gt;&gt;&gt; scaler.transform([[-1., 1., 0.]]) array([[-2.44..., 1.22..., -0.26...]]) MinMax标准化(最小最大值标准化)将数据缩放至给定的最小值与最大值之间，通常是０与１之间，可用MinMaxScaler实现。或者将最大的绝对值缩放至单位大小，可用MaxAbsScaler实现。对原始数据的线性变换，使结果落到[0,1]区间，转换函数如下：x ＝ (x - min)/(max - min)max: 样本数据的最大值min: 为样本数据的最小值使用这种方法的目的包括：1、对于方差非常小的属性可以增强其稳定性。2、维持稀疏矩阵中为0的条目。sklearn实现MinMax标准化：123456789101112131415161718192021222324&gt;&gt;&gt; X_train = np.array([[ 1., -1., 2.],... [ 2., 0., 0.],... [ 0., 1., -1.]])...&gt;&gt;&gt; min_max_scaler = preprocessing.MinMaxScaler()&gt;&gt;&gt; X_train_minmax = min_max_scaler.fit_transform(X_train)&gt;&gt;&gt; X_train_minmaxarray([[ 0.5 , 0. , 1. ], [ 1. , 0.5 , 0.33333333], [ 0. , 1. , 0. ]]) &gt;&gt;&gt; #将相同的缩放应用到测试集数据中&gt;&gt;&gt; X_test = np.array([[ -3., -1., 4.]])&gt;&gt;&gt; X_test_minmax = min_max_scaler.transform(X_test)&gt;&gt;&gt; X_test_minmaxarray([[-1.5 , 0. , 1.66666667]]) &gt;&gt;&gt; #缩放因子等属性&gt;&gt;&gt; min_max_scaler.scale_ array([ 0.5 , 0.5 , 0.33...]) &gt;&gt;&gt; min_max_scaler.min_ array([ 0. , 0.5 , 0.33...]) MinMaxScaler()默认的缩放范围是（0,1）。在构造类对象的时候也可以直接指定最大最小值的范围：feature_range=(min, max)例如：min_max_scaler = preprocessing.MinMaxScaler(feature_range=(min, max)) MaxAbsScaler（绝对值最大标准化）与上述标准化方法相似，但是它通过除以最大值将训练集缩放至[-1,1]123456789X_train = np.array([[ 1., -1., 2.], [ 2., 0., 0.], [ 0., 1., -1.]]) max_abs_scaler = preprocessing.MaxAbsScaler() X_train_maxabs = max_abs_scaler.fit_transform(X_train) # doctest +NORMALIZE_WHITESPACE^, out: array([[ 0.5, -1., 1. ], [ 1. , 0. , 0. ], [ 0. , 1. , -0.5]]) X_test = np.array([[ -3., -1., 4.]]) X_test_maxabs = max_abs_scaler.transform(X_test) #out: array([[-1.5, -1. , 2. ]]) max_abs_scaler.scale_ #out: array([ 2., 1., 2.]) 正则化（Normalization）规范化这个本人理解的不是很透，先把别人的结论放上来。而且从找到的资料来看，这个翻译比较模糊。文档上说：Normalization is the process of scaling individual samples to have unit norm.正则化的过程是将每个样本缩放到单位范数（每个样本的范数为1），如果后面要使用如二次型（点积）或者其它核方法计算两个样本之间的相似性这个方法会很有用。将样本缩放成单位向量，标准化数据是针对特征来说的，而现在正则化是对样本来做的，是用样本数据除以他的范式。sklearn实现使用preprocessing.normalize(x, norm = ‘l1’)方法，具体的参数说明详见sklearn文档http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize1.使用preprocessing.normalize()函数对指定数据进行转换：123456789&gt;&gt;&gt; X = [[ 1., -1., 2.],... [ 2., 0., 0.],... [ 0., 1., -1.]]&gt;&gt;&gt; X_normalized = preprocessing.normalize(X, norm='l2') &gt;&gt;&gt; X_normalized array([[ 0.40..., -0.40..., 0.81...], [ 1. ..., 0. ..., 0. ...], [ 0. ..., 0.70..., -0.70...]]) 2.使用processing.Normalizer()类实现对训练集和测试集的拟合和转换：123456789101112&gt;&gt;&gt; normalizer = preprocessing.Normalizer().fit(X) # fit does nothing&gt;&gt;&gt; normalizerNormalizer(copy=True, norm='l2') &gt;&gt;&gt;&gt;&gt;&gt; normalizer.transform(X) array([[ 0.40..., -0.40..., 0.81...], [ 1. ..., 0. ..., 0. ...], [ 0. ..., 0.70..., -0.70...]]) &gt;&gt;&gt; normalizer.transform([[-1., 1., 0.]]) array([[-0.70..., 0.70..., 0. ...]]) 对于l2 norm,变换后每个样本的各维特征的平方和为1。类似地，L1 norm则是变换后每个样本的各维特征的绝对值和为1。还有max norm，则是将每个样本的各维特征除以该样本各维特征的最大值. 二值化（Binarization）将数值型数据转化为布尔型的二值数据，可以设置一个阈值（threshold）在sklearn中，sklearn.preprocessing.Binarizer函数可以实现123456789101112&gt;&gt;&gt; X = [[ 1., -1., 2.],... [ 2., 0., 0.],... [ 0., 1., -1.]]&gt;&gt;&gt; binarizer = preprocessing.Binarizer().fit(X) # fit does nothing&gt;&gt;&gt; binarizerBinarizer(copy=True, threshold=0.0)&gt;&gt;&gt; binarizer.transform(X)array([[ 1., 0., 1.], [ 1., 0., 0.], [ 0., 1., 0.]]) 而且还可以调整阈值12345&gt;&gt;&gt; binarizer = preprocessing.Binarizer(threshold=1.1)&gt;&gt;&gt; binarizer.transform(X)array([[ 0., 0., 1.], [ 1., 0., 0.], [ 0., 0., 0.]]) 标签预处理（Label preprocessing）标签二值化（Label binarization）LabelBinarizer通常用于通过一个多类标签（label）列表，创建一个label指示器矩阵12345678&gt;&gt;&gt; lb = preprocessing.LabelBinarizer()&gt;&gt;&gt; lb.fit([1, 2, 6, 4, 2])LabelBinarizer(neg_label=0, pos_label=1)&gt;&gt;&gt; lb.classes_array([1, 2, 4, 6])&gt;&gt;&gt; lb.transform([1, 6])array([[1, 0, 0, 0], [0, 0, 0, 1]]) 上例中每个实例中只有一个标签（label），LabelBinarizer也支持每个实例数据显示多个标签：12345&gt;&gt;&gt; lb.fit_transform([(1, 2), (3,)]) #(1,2)实例中就包含两个labelarray([[1, 1, 0], [0, 0, 1]])&gt;&gt;&gt; lb.classes_array([1, 2, 3]) 标签编码（Label encoding）12345678910&gt;&gt;&gt; from sklearn import preprocessing&gt;&gt;&gt; le = preprocessing.LabelEncoder()&gt;&gt;&gt; le.fit([1, 2, 2, 6])LabelEncoder()&gt;&gt;&gt; le.classes_array([1, 2, 6])&gt;&gt;&gt; le.transform([1, 1, 2, 6])array([0, 0, 1, 2])&gt;&gt;&gt; le.inverse_transform([0, 0, 1, 2])array([1, 1, 2, 6]) 也可以用于非数值类型的标签到数值类型标签的转化：123456789&gt;&gt;&gt; le = preprocessing.LabelEncoder()&gt;&gt;&gt; le.fit(["paris", "paris", "tokyo", "amsterdam"])LabelEncoder()&gt;&gt;&gt; list(le.classes_)['amsterdam', 'paris', 'tokyo']&gt;&gt;&gt; le.transform(["tokyo", "tokyo", "paris"])array([2, 2, 1])&gt;&gt;&gt; list(le.inverse_transform([2, 2, 1]))['tokyo', 'tokyo', 'paris'] 离散变量编码例如性别有‘男’， ‘女’，然而计算机的许多模型都只能在数值型数据当中进行计算，如果我们简单的将‘男’为1，‘女’为0，虽然也可以完成转换，但是在转换的过程当中我们引入了大小关系，就是‘女’ &lt; ‘男’，这会对后续模型应用造成不必要的困扰。解决方法为OneHotEncode，就是将其转化为二进制串，除了当前值所在位置为1，其他全部为0，如[0,0,1,0,0], [0,1,0,0,0].。性别可表示为男为[1,0]，女为[0,1]，这样一个性别特征就转化成了两个特征。1234567df = pd.DataFrame(&#123;'pet': ['cat', 'dog', 'dog', 'fish'],'age': [4 , 6, 3, 3],'salary':[4, 5, 1, 1]&#125;)#例如有数据比较大，OneHotEncoder会生成非常多的特征，或者为字符串数据，先转化为数字，所以先用LabelEncoder处理。label = preprocessing.LabelEncoder()df['pet'] = label.fit_transform(df['pet'])one_hot = preprocessing.OneHotEncoder(sparse = False)print one_hot.fit_transform(df[['pet']]) 1234567891011before age pet salary0 4 0 41 6 1 52 3 1 13 3 2 1after[[ 1. 0. 0.] [ 0. 1. 0.] [ 0. 1. 0.] [ 0. 0. 1.]] 缺失值处理sklearn中的Imputer类提供了一些基本的方法来处理缺失值，如使用均值、中位值或者缺失值所在列中频繁出现的值来替换。例如使用均值来处理的实例：12345678910&gt;&gt;&gt; import numpy as np &gt;&gt;&gt; from sklearn.preprocessing import Imputer &gt;&gt;&gt; imp = Imputer(missing_values='NaN', strategy='mean', axis=0) &gt;&gt;&gt; imp.fit([[1, 2], [np.nan, 3], [7, 6]]) Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0) &gt;&gt;&gt; X = [[np.nan, 2], [6, np.nan], [7, 6]] &gt;&gt;&gt; print(imp.transform(X)) [[ 4. 2. ] [ 6. 3.666...] [ 7. 6. ]] Imputer也支持稀疏矩阵作为输入：12345678910&gt;&gt;&gt; import scipy.sparse as sp&gt;&gt;&gt; X = sp.csc_matrix([[1, 2], [0, 3], [7, 6]])&gt;&gt;&gt; imp = Imputer(missing_values=0, strategy='mean', axis=0)&gt;&gt;&gt; imp.fit(X)Imputer(axis=0, copy=True, missing_values=0, strategy='mean', verbose=0)&gt;&gt;&gt; X_test = sp.csc_matrix([[0, 2], [6, 0], [7, 6]])&gt;&gt;&gt; print(imp.transform(X_test)) [[ 4. 2. ] [ 6. 3.666...] [ 7. 6. ]] 维度拓展考虑复杂化非线性特征，就是生成多项式特征，例如(x1,x2)−&gt;(x1,x2,x21,x1x2,x22)，会使特征数量增加1234567891011poly = PolynomialFeatures(2)#参数为阶数poly.fit_transform(X) '''before [[0, 1], [2, 3], [4, 5]]after[[ 1., 0., 1., 0., 0., 1.], [ 1., 2., 3., 4., 6., 9.], [ 1., 4., 5., 16., 20., 25.]] 参考：http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-normalizationhttp://blog.csdn.net/u010787640/article/details/60956164http://blog.csdn.net/shmily_skx/article/details/52946414http://www.cnblogs.com/chaosimple/p/4153167.htmlhttp://blog.csdn.net/csmqq/article/details/51461696]]></content>
      <categories>
        <category>sklearn学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次坑爹的windows下安装xgboost的经历]]></title>
    <url>%2F2017%2F06%2F05%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%9D%91%E7%88%B9%E7%9A%84windows%E4%B8%8B%E5%AE%89%E8%A3%85xgboost%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[近来做一个比赛，一个识别鼠标轨迹是人还是机器的二分类问题。自己用SVM和神经网络等传统的机器学习的方法都试过了，但是提交之后的结果发现并不好。正好前几天研究过几个别人做的其他比赛的解决方案，发现用的boosting方法比较多,其中尤其是xgboost。于是打算再用xgboost的模型做一下，看看结果怎么样。但是，安装xgboost的过程并不轻松。试了好几种方法，最后花了一下午时间，终于安装成功。 1.使用纯命令行安装参考：http://www.th7.cn/system/win/201603/157092.shtmlhttp://blog.csdn.net/ychanmy/article/details/5097253012345678$ git clone --recursive https://github.com/dmlc/xgboost$ cd xgboost$ git submodule init$ git submodule update$cp make/mingw64.mk config.mk$make -j4$cd python-package$python setup.py install 但是，为毛别人都能成功，我就是一直报错呢，而且google不到答案，哎。。。看来这个东西看人品的，没办法，找其他的办法吧！ 2.使用旧版本的xgboost最终，在http://m.blog.csdn.net/article/details?id=53118803找到一个可用的解决方法。下载旧版本的xgboost,http://download.csdn.net/detail/zhuqiuhui/9476012然后就很简单。12345$cd xgboost$make -j4$cd python-package$python setup.py install 终于！不知道旧版本的xgbosot有没有什么问题，先用用试试吧！]]></content>
      <categories>
        <category>大数据比赛</category>
      </categories>
      <tags>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sklearn PCA降维]]></title>
    <url>%2F2017%2F06%2F01%2Fsklearn-PCA%E9%99%8D%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[对于太多的特征，一般需要进行降维处理。PCA是最常用的降维的方法，sklearn提供了PCA降维的方法。 函数原型1class sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False, svd_solver=&apos;auto&apos;, tol=0.0, iterated_power=&apos;auto&apos;, random_state=None) 主要参数 n_components:意义：PCA算法中所要保留的主成分个数n，也即保留下来的特征个数n类型：int 或者 string，缺省时默认为None，所有成分被保留。 赋值为int，比如n_components=1，将把原始数据降到一个维度。 赋值为string，比如n_components=’mle’，将自动选取特征个数n，使得满足所要求的方差百分比。 copy:类型：bool，True或者False，缺省时默认为True。意义：表示是否在运行算法时，将原始训练数据复制一份。若为True，则运行PCA算法后，原始训练数据的值不 会有任何改变，因为是在原始数据的副本上进行运算；若为False，则运行PCA算法后，原始训练数据的 值会改，因为是在原始数据上进行降维计算。 whiten:类型：bool，缺省时默认为False意义：白化，使得每个特征具有相同的方差。 属性和参数差不多，参考http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html 方法fit(X[, y]) —— Fit the model with X.fit_transform(X[, y])—— Fit the model with X and apply the dimensionality reduction on X.get_covariance() —— Compute data covariance with the generative model.get_params([deep]) —— Get parameters for this estimator.get_precision() —— Compute data precision matrix with the generative model.inverse_transform(X) —— Transform data back to its original space, i.e.,score(X[, y]) —— Return the average log-likelihood of all samplesscore_samples(X) —— Return the log-likelihood of each sampleset_params(**params) —— Set the parameters of this estimator.transform(X) —— Apply the dimensionality reduction on X.详细说明： fit(X,y=None)fit()可以说是scikit-learn中通用的方法，每个需要训练的算法都会有fit()方法，它其实就是算法中的“训练”这一步骤。因为PCA是无监督学习算法，此处y自然等于None。 fit(X)，表示用数据X来训练PCA模型。函数返回值：调用fit方法的对象本身。比如pca.fit(X)，表示用X对pca这个对象进行训练。 fit_transform(X)用X来训练PCA模型，同时返回降维后的数据。newX=pca.fit_transform(X)，newX就是降维后的数据。 inverse_transform()将降维后的数据转换成原始数据，X=pca.inverse_transform(newX) transform(X)将数据X转换成降维后的数据。当模型训练好后，对于新输入的数据，都可以用transform方法来降维。此外，还有get_covariance()、get_precision()、get_params(deep=True)、score(X, y=None)等方法，参考上面的英文。Example以一组二维的数据data为例，data如下，一共12个样本（x,y），其实就是分布在直线y=x上的点，并且聚集在x=1、2、3、4上，各3个。12345678910111213&gt;&gt;&gt; data array([[ 1. , 1. ], [ 0.9 , 0.95], [ 1.01, 1.03], [ 2. , 2. ], [ 2.03, 2.06], [ 1.98, 1.89], [ 3. , 3. ], [ 3.03, 3.05], [ 2.89, 3.1 ], [ 4. , 4. ], [ 4.06, 4.02], [ 3.97, 4.01]]) data这组数据，有两个特征，因为两个特征是近似相等的，所以用一个特征就能表示了，即可以降到一维。下面就来看看怎么用sklearn中的PCA算法包。（1）n_components设置为1，copy默认为True，可以看到原始数据data并未改变，newData是一维的，并且明显地将原始数据分成了四类。1234567891011121314151617181920212223242526272829&gt;&gt;&gt; from sklearn.decomposition import PCA &gt;&gt;&gt; pca=PCA(n_components=1) &gt;&gt;&gt; newData=pca.fit_transform(data) &gt;&gt;&gt; newData array([[-2.12015916], [-2.22617682], [-2.09185561], [-0.70594692], [-0.64227841], [-0.79795758], [ 0.70826533], [ 0.76485312], [ 0.70139695], [ 2.12247757], [ 2.17900746], [ 2.10837406]]) &gt;&gt;&gt; data array([[ 1. , 1. ], [ 0.9 , 0.95], [ 1.01, 1.03], [ 2. , 2. ], [ 2.03, 2.06], [ 1.98, 1.89], [ 3. , 3. ], [ 3.03, 3.05], [ 2.89, 3.1 ], [ 4. , 4. ], [ 4.06, 4.02], [ 3.97, 4.01]]) （2）将copy设置为False，原始数据data将发生改变。123456789101112131415&gt;&gt;&gt; pca=PCA(n_components=1,copy=False) &gt;&gt;&gt; newData=pca.fit_transform(data) &gt;&gt;&gt; data array([[-1.48916667, -1.50916667], [-1.58916667, -1.55916667], [-1.47916667, -1.47916667], [-0.48916667, -0.50916667], [-0.45916667, -0.44916667], [-0.50916667, -0.61916667], [ 0.51083333, 0.49083333], [ 0.54083333, 0.54083333], [ 0.40083333, 0.59083333], [ 1.51083333, 1.49083333], [ 1.57083333, 1.51083333], [ 1.48083333, 1.50083333]]) （3）n_components设置为’mle’，看看效果，自动降到了1维。123456789101112131415&gt;&gt;&gt; pca=PCA(n_components='mle') &gt;&gt;&gt; newData=pca.fit_transform(data) &gt;&gt;&gt; newData array([[-2.12015916], [-2.22617682], [-2.09185561], [-0.70594692], [-0.64227841], [-0.79795758], [ 0.70826533], [ 0.76485312], [ 0.70139695], [ 2.12247757], [ 2.17900746], [ 2.10837406]]) （4）对象的属性值12345678&gt;&gt;&gt; pca.n_components 1 &gt;&gt;&gt; pca.explained_variance_ratio_ array([ 0.99910873]) &gt;&gt;&gt; pca.explained_variance_ array([ 2.55427003]) &gt;&gt;&gt; pca.get_params &lt;bound method PCA.get_params of PCA(copy=True, n_components=1, whiten=False)&gt; 我们所训练的pca对象的n_components值为1，即保留1个特征，该特征的方差为2.55427003，占所有特征的方差百分比为0.99910873，意味着几乎保留了所有的信息。get_params返回各个参数的值。（5）对象的方法123456&gt;&gt;&gt; newA=pca.transform(A)``` 对新的数据A，用已训练好的pca模型进行降维。```python&gt;&gt;&gt; pca.set_params(copy=False) PCA(copy=False, n_components=1, whiten=False) 设置参数。 示例在一个论坛上看到的例子123456789101112131415161718192021222324252627282930313233343536373839404142#导入数值计算库import numpy as np#导入科学计算库import pandas as pd#导入数据预处理库from sklearn.preprocessing import StandardScaler#导入PCA算法库from sklearn.decomposition import PCA#读取贷款状态数据从创建名为LoanStats3a的数据表LoanStats3a=pd.DataFrame(pd.read_csv('LoanStats3a.csv')) #查看数据表内容LoanStats3a.head()#删除包含空值的特征LoanStats3a=LoanStats3a.dropna()#设置特征表X#将贷款数据表中的贷款特征数据单独提取出来，用于后面的降维操作。X = np.array(LoanStats3a[['loan_amnt', 'funded_amnt_inv', 'installment','annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc','pub_rec', 'revol_bal', 'total_acc', 'out_prncp', 'out_prncp_inv','total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int','total_rec_late_fee', 'recoveries', 'collection_recovery_fee','last_pymnt_amnt']])#对特征数据进行标准化处理,去除不同数据的单位限制，将它们转化为无量纲的纯数值。sc = StandardScaler()X_std = sc.fit_transform(X)#创建PCA对象，n_components=3pca = decomposition.PCA(n_components=3)#使用PCA对特征进行降维X_std_pca = pca.fit_transform(X_std)#下面的写法与上面相同,下面进行了白化变换，数据还原之后进行了方差的归一化pca=PCA(n_components=6,whiten=True)pca.fit(X_std)newData=pca.transform(X_std)X=pca.inverse_transform(newData) 本文参考：http://blog.csdn.net/u012162613/article/details/42192293 http://www.aboutyun.com/thread-21655-1-1.html]]></content>
      <categories>
        <category>sklearn学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lightgbm python接口的安装]]></title>
    <url>%2F2017%2F05%2F31%2Flightgbm-python%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[最近看一些大数据比赛大神们开源的解决方案，发现他们经常使用所谓数据挖掘三驾马车。恶补了一下boosting方法.现在把lightgbm的python接口的安装过程记录下来，免得以后忘了。LightGBM（Light Gradient Boosting Machine）是一个基于决策树算法的快速的、分布式的、高性能 gradient boosting（GBDT、GBRT、GBM 或 MART）框架，可被用于排行、分类以及其他许多机器学习任务中。开源项目地址： https://github.com/Microsoft/LightGBM优势： 更快的训练效率低内存使用更好的准确率支持并行学习可处理大规模数据 1.下载源码1git clone --recursive https://github.com/Microsoft/LightGBM 2.编译dll进入下载的LightGBM目录下，用VS打开windows/LightGBM.sln，生成时选择DLL和x64，然后进行编译。dll文件就会在windows/x64/DLL/目录里。 3.安装python包进入目录python-package，执行命令python setup.py install 4.测试是否安装成功进入examples\python-guide，执行样例python .\simple_example.py如果没有报错，那就说明安装成功了！]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo个人域名配置]]></title>
    <url>%2F2017%2F05%2F31%2Fhexo%E4%B8%AA%E4%BA%BA%E5%9F%9F%E5%90%8D%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1.在万网上购买域名https://wanwang.aliyun.com 或者其他域名购买网站 2.配置域名解析进入你的管理后台 3.添加域名解析按下图所示添加域名解析。其中，记录类型选A或CNAME，A记录的记录值就是ip地址，github(官方文档)提供了两个IP地址，192.30.252.153和192.30.252.154，这两个IP地址为github的服务器地址，两个都要填上，解析记录设置两个www和@，线路就默认就行了，CNAME记录值填你的github博客网址。 4.创建CNAME文件 这些全部设置完成后，此时你并不能要申请的域名访问你的博客。接着你需要做的是在hexo根目录的source文件夹里创建CNAME文件，不带任何后缀，里面添加你的域名信息，如：xiaoyb.me。 5.发布并访问重新发布hexo d -g然后就可以访问你的新域名了。快点试试吧！]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>域名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eclipse下创建maven webapp项目]]></title>
    <url>%2F2017%2F04%2F22%2Feclipse%E4%B8%8B%E5%88%9B%E5%BB%BAmaven-webapp%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[1、开启eclipse，右键new——》other，如下图找到maven project2、选择maven project，显示创建maven项目的窗口，勾选如图所示，Create a simple project3、输入maven项目的基本信息，如下图所示：4、完成maven项目的创建，生成相应的maven项目结果，如下所示，此处有部分结构是项目不需要的，我们需要去掉：5、选择项目，右键选择Properties，进入属性页面，选择到Maven菜单下，如下图所示：6、选择java版本为1.7，并去掉其他两项，如下图：7、点击ok之后，再次回到项目结构，此时项目结构比较清晰，符合我们想要创建的maven项目8、此时webapp下的结果还没有显示出来，因为此时我们还没有配置此的项目为web项目，再次进去Properties配置，如下图所示：9、点击Further configuration available…，如下：10、配置src/main/webapp，并勾选生成web.xml的选项，如下：11、确定之后，返回到maven菜单下去掉Dynamic Web Module的勾选，点击ok，如下所示，webapp目录结构显示出来了：12、此时还需要配置，src/main/webapp为“/”项目的根目录，如下所示：13、完成如上配置后，最后完成maven webapp项目结构如下图所示：]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>javaweb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么新生代需要两个Survivor区]]></title>
    <url>%2F2017%2F04%2F12%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%96%B0%E7%94%9F%E4%BB%A3%E9%9C%80%E8%A6%81%E4%B8%A4%E4%B8%AASurvivor%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[在JVM的新生代内存中，为什么除了Eden区，还要设置两个Survivor区？ 为什么要有Survivor区先不去想为什么有两个Survivor区，第一个问题是，设置Survivor区的意义在哪里？堆内存分类如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代。老年代很快被填满，触发Major GC（因为Major GC一般伴随着Minor GC，也可以看做触发了Full GC）。老年代的内存空间远大于新生代，进行一次Full GC消耗的时间比Minor GC长得多。你也许会问，执行时间长有什么坏处？频发的Full GC消耗的时间是非常可观的，这一点会影响大型程序的执行和响应速度，更不要说某些连接会因为超时发生连接错误了。 好，那我们来想想在没有Survivor的情况下，有没有什么解决办法，可以避免上述情况：显而易见，没有Survivor的话，上述两种解决方案都不能从根本上解决问题。 我们可以得到第一条结论：Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。 为什么要设置两个Survivor区设置两个Survivor区最大的好处就是解决了碎片化 下面我们来分析一下。 为什么一个Survivor区不行？第一部分中，我们知道了必须设置Survivor区。假设现在只有一个survivor区，我们来模拟一下流程：刚刚新建的对象在Eden中，一旦Eden满了，触发一次Minor GC，Eden中的存活对象就会被移动到Survivor区。这样继续循环下去，下一次Eden满了的时候，问题来了，此时进行Minor GC，Eden和Survivor各有一些存活对象，如果此时把Eden区的存活对象硬放到Survivor区，很明显这两部分对象所占有的内存是不连续的，也就导致了内存碎片化。我绘制了一幅图来表明这个过程。其中色块代表对象，白色框分别代表Eden区（大）和Survivor区（小）。Eden区理所当然大一些，否则新建对象很快就导致Eden区满，进而触发Minor GC，有悖于初衷。一个Survivor区带来碎片化 碎片化带来的风险是极大的，严重影响Java程序的性能。堆空间被散布的对象占据不连续的内存，最直接的结果就是，堆中没有足够大的连续内存空间，接下去如果程序需要给一个内存需求很大的对象分配内存。。。画面太美不敢看。。。这就好比我们爬山的时候，背包里所有东西紧挨着放，最后就可能省出一块完整的空间放相机。如果每件行李之间隔一点空隙乱放，很可能最后就要一路把相机挂在脖子上了。 那么，顺理成章的，应该建立两块Survivor区，刚刚新建的对象在Eden中，经历一次Minor GC，Eden中的存活对象就会被移动到第一块survivor space S0，Eden被清空；等Eden区再满了，就再触发一次Minor GC，Eden和S0中的存活对象又会被复制送入第二块survivor space S1（这个过程非常重要，因为这种复制算法保证了S1中来自S0和Eden两部分的存活对象占用连续的内存空间，避免了碎片化的发生）。S0和Eden被清空，然后下一轮S0与S1交换角色，如此循环往复。如果对象的复制次数达到16次，该对象就会被送到老年代中。下图中每部分的意义和上一张图一样，就不加注释了。两块Survivor避免碎片化上述机制最大的好处就是，整个过程中，永远有一个survivor space是空的，另一个非空的survivor space无碎片。 那么，Survivor为什么不分更多块呢？比方说分成三个、四个、五个?显然，如果Survivor区再细分下去，每一块的空间就会比较小，很容易导致Survivor区满，因此，我认为两块Survivor区是经过权衡之后的最佳方案。 转自：http://blog.csdn.net/antony9118/article/details/51425581]]></content>
      <categories>
        <category>java虚拟机</category>
      </categories>
      <tags>
        <tag>java虚拟机</tag>
        <tag>垃圾回收</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回溯算法详解]]></title>
    <url>%2F2017%2F04%2F11%2F%E5%9B%9E%E6%9C%94%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[刷题的时候碰到一个很常见的算法-回溯法，看了一些博客，感觉这个讲得通俗易懂。转过来，后面有些自己的补充。&emsp;&emsp;回溯法（探索与回溯法）是一种选优搜索法，又称为试探法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。首先我们来看一道题目：Combinations：Given two integers n and k,return all possible combinations of k numbersout of 1 … n. For example, If n = 4 and k =2, a solution is: [ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4],]（做一个白话版的描述，给你两个整数 n和k，从1-n中选择k个数字的组合。比如n=4，那么从1,2,3,4中选取两个数字的组合，包括图上所述的四种。）然后我们看看题目给出的框架：1234public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123; &#125;&#125; 要求返回的类型是List&lt;List&gt; 也就是说将所有可能的组合list（由整数构成）放入另一个list（由list构成）中。现在进行套路教学：要求返回List&lt;List&gt;，那我就给你一个List&lt;List&gt;，因此 定义一个全局List&lt;List&gt; result=new ArrayList&lt;List&gt;(); 定义一个辅助的方法（函数）public void backtracking(int n,int k, Listlist){}n k 总是要有的吧，加上这两个参数，前面提到List 是数字的组合，也是需要的吧，这三个是必须的，没问题吧。（可以尝试性地写参数，最后不需要的删除） 接着就是我们的重头戏了，如何实现这个算法？对于n=4，k=2，1,2,3,4中选2个数字，我们可以做如下尝试，加入先选择1，那我们只需要再选择一个数字，注意这时候k=1了（此时只需要选择1个数字啦）。当然，我们也可以先选择2,3 或者4，通俗化一点，我们可以选择（1-n）的所有数字，这个是可以用一个循环来描述？每次选择一个加入我们的链表list中，下一次只要再选择k-1个数字。那什么时候结束呢？当然是k&lt;0的时候啦，这时候都选完了。有了上面的分析，我们可以开始填写public void backtracking(int n,int k, List list){}中的内容。12345678910111213public void backtracking(int n,int k,int start,List&lt;Integer&gt; list)&#123; if(k&lt;0) return; else if(k==0)&#123; //k==0表示已经找到了k个数字的组合，这时候加入全局result中 result.add(new ArrayList(list)); &#125;else&#123; for(int i=start;i&lt;=n;i++)&#123; list.add(i);//尝试性的加入i //开始回溯啦，下一次要找的数字减少一个所以用k-1，i+1见后面分析 backtracking(n,k-1,i+1,list); //（留白，有用=。=） &#125; &#125; &#125; 观察一下上述代码，我们加入了一个start变量，它是i的起点。为什么要加入它呢？比如我们第一次加入了1，下一次搜索的时候还能再搜索1了么？肯定不可以啊！我们必须从他的下一个数字开始，也就是2 、3或者4啦。所以start就是一个开始标记这个很重要啦！这时候我们在主方法中加入backtracking(n,k,1,list);调试后发现答案不对啊！为什么我的答案比他长那么多？ 回溯回溯当然要退回再走啦，你不退回，当然又臭又长了！所以我们要在刚才代码注释留白处加上退回语句。仔细分析刚才的过程，我们每次找到了1,2这一对答案以后，下一次希望2退出然后让3进来，1 3就是我们要找的下一个组合。如果不回退，找到了2 ，3又进来，找到了3，4又进来，所以就出现了我们的错误答案。正确的做法就是加上：list.remove(list.size()-1);他的作用就是每次清除一个空位 让后续元素加入。寻找成功，最后一个元素要退位，寻找不到，方法不可行，那么我们回退，也要移除最后一个元素。所以完整的程序如下：1234567891011121314151617181920public class Solution &#123; List&lt;List&lt;Integer&gt;&gt; result=new ArrayList&lt;List&lt;Integer&gt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123; List&lt;Integer&gt; list=new ArrayList&lt;Integer&gt;(); backtracking(n,k,1,list); return result; &#125; public void backtracking(int n,int k,int start,List&lt;Integer&gt;list)&#123; if(k&lt;0) return ; else if(k==0)&#123; result.add(new ArrayList(list)); &#125;else&#123; for(int i=start;i&lt;=n;i++)&#123; list.add(i); backtracking(n,k-1,i+1,list); list.remove(list.size()-1); &#125; &#125; &#125; &#125; 是不是有点想法了？那么我们操刀一下。Combination SumGiven a set ofcandidate numbers (C) and a target number (T), findall unique combinations in C where thecandidate numbers sums toT.The same repeated numbermay be chosen from C unlimited numberof times.Note:All numbers (including target) will be positive integers.The solution set must not contain duplicate combinations.For example,given candidate set [2, 3, 6, 7] and target 7,A solution set is:[ [7], [2,2, 3]]（容我啰嗦地白话下，给你一个正数数组candidate[],一个目标值target，寻找里面所有的不重复组合，让其和等于target，给你[2,3,6,7] 2+2+3=7 ,7=7,所以可能组合为[2,2,3],[7]）按照前述的套路走一遍：12345678910public class Solution &#123; List&lt;List&lt;Integer&gt;&gt; result=new ArrayList&lt;List&lt;Integer&gt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates,int target) &#123; Arrays.sort(candidates); List&lt;Integer&gt; list=new ArrayList&lt;Integer&gt;(); return result; &#125; public void backtracking(int[] candidates,int target,int start,)&#123; &#125;&#125; 全局List&lt;List&gt; result先定义 回溯backtracking方法要定义，数组candidates 目标target 开头start 辅助链表List list都加上。 分析算法：以[2,3,6,7] 每次尝试加入数组任何一个值，用循环来描述，表示依次选定一个值123for(inti=start;i&lt;candidates.length;i++)&#123; list.add(candidates[i]); &#125; 接下来回溯方法再调用。比如第一次选了2，下次还能再选2是吧，所以每次start都可以从当前i开始（ps：如果不允许重复，从i+1开始）。第一次选择2，下一次要凑的数就不是7了，而是7-2，也就是5，一般化就是remain=target-candidates[i],所以回溯方法为：backtracking(candidates,target-candidates[i],i,list);然后加上退回语句：list.remove(list.size()-1);那么什么时候找到的解符合要求呢？自然是remain（注意区分初始的target）=0了，表示之前的组合恰好能凑出target。如果remain0 说明凑的还不够，继续凑。所以完整方法如下：123456789101112131415161718192021222324public class Solution &#123; List&lt;List&lt;Integer&gt;&gt; result=newArrayList&lt;List&lt;Integer&gt;&gt;(); public List&lt;List&lt;Integer&gt;&gt;combinationSum(int[] candidates, int target) &#123; Arrays.sort(candidates);//所给数组可能无序，排序保证解按照非递减组合 List&lt;Integer&gt; list=newArrayList&lt;Integer&gt;(); backtracking(candidates,target,0,list);//给定target，start=0表示从数组第一个开始 return result;//返回解的组合链表 &#125; public void backtracking(int[]candidates,int target,int start,List&lt;Integer&gt; list)&#123; if(target&lt;0) return;//凑过头了 else if(target==0)&#123; result.add(newArrayList&lt;&gt;(list));//正好凑出答案，开心地加入解的链表 &#125;else&#123; for(int i=start;i&lt;candidates.length;i++)&#123;//循环试探每个数 list.add(candidates[i]);//尝试加入 //下一次凑target-candidates[i]，允许重复，还是从i开始 backtracking(candidates,target-candidates[i],i,list); list.remove(list.size()-1);//回退 &#125; &#125; &#125; &#125; 是不是觉得还是有迹可循的？下一篇博客将部分回溯算法拿出来，供大家更好地发现其中的套路。This structure might apply to many other backtracking questions, but here I am just going to demonstrate Subsets, Permutations, and Combination Sum. Subsets : https://leetcode.com/problems/subsets/123456789101112131415public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); Arrays.sort(nums); backtrack(list, new ArrayList&lt;&gt;(), nums, 0); return list;&#125;private void backtrack(List&lt;List&lt;Integer&gt;&gt; list , List&lt;Integer&gt; tempList, int [] nums, int start)&#123; list.add(new ArrayList&lt;&gt;(tempList)); for(int i = start; i &lt; nums.length; i++)&#123; tempList.add(nums[i]); backtrack(list, tempList, nums, i + 1); tempList.remove(tempList.size() - 1); &#125;&#125; Subsets II (contains duplicates) : https://leetcode.com/problems/subsets-ii/12345678910111213141516public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); Arrays.sort(nums); backtrack(list, new ArrayList&lt;&gt;(), nums, 0); return list;&#125;private void backtrack(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, int [] nums, int start)&#123; list.add(new ArrayList&lt;&gt;(tempList)); for(int i = start; i &lt; nums.length; i++)&#123; if(i &gt; start &amp;&amp; nums[i] == nums[i-1]) continue; // skip duplicates tempList.add(nums[i]); backtrack(list, tempList, nums, i + 1); tempList.remove(tempList.size() - 1); &#125;&#125; Permutations : https://leetcode.com/problems/permutations/12345678910111213141516171819public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); // Arrays.sort(nums); // not necessary backtrack(list, new ArrayList&lt;&gt;(), nums); return list;&#125;private void backtrack(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, int [] nums)&#123; if(tempList.size() == nums.length)&#123; list.add(new ArrayList&lt;&gt;(tempList)); &#125; else&#123; for(int i = 0; i &lt; nums.length; i++)&#123; if(tempList.contains(nums[i])) continue; // element already exists, skip tempList.add(nums[i]); backtrack(list, tempList, nums); tempList.remove(tempList.size() - 1); &#125; &#125;&#125; Permutations II (contains duplicates) : https://leetcode.com/problems/permutations-ii/123456789101112131415161718192021public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); Arrays.sort(nums); backtrack(list, new ArrayList&lt;&gt;(), nums, new boolean[nums.length]); return list;&#125;private void backtrack(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, int [] nums, boolean [] used)&#123; if(tempList.size() == nums.length)&#123; list.add(new ArrayList&lt;&gt;(tempList)); &#125; else&#123; for(int i = 0; i &lt; nums.length; i++)&#123; if(used[i] || i &gt; 0 &amp;&amp; nums[i] == nums[i-1] &amp;&amp; !used[i - 1]) continue; used[i] = true; tempList.add(nums[i]); backtrack(list, tempList, nums, used); used[i] = false; tempList.remove(tempList.size() - 1); &#125; &#125;&#125; Combination Sum : https://leetcode.com/problems/combination-sum/123456789101112131415161718public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] nums, int target) &#123; List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); Arrays.sort(nums); backtrack(list, new ArrayList&lt;&gt;(), nums, target, 0); return list;&#125;private void backtrack(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, int [] nums, int remain, int start)&#123; if(remain &lt; 0) return; else if(remain == 0) list.add(new ArrayList&lt;&gt;(tempList)); else&#123; for(int i = start; i &lt; nums.length; i++)&#123; tempList.add(nums[i]); backtrack(list, tempList, nums, remain - nums[i], i); // not i + 1 because we can reuse same elements tempList.remove(tempList.size() - 1); &#125; &#125;&#125; Combination Sum II (can’t reuse same element) : https://leetcode.com/problems/combination-sum-ii/1234567891011121314151617181920public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] nums, int target) &#123; List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); Arrays.sort(nums); backtrack(list, new ArrayList&lt;&gt;(), nums, target, 0); return list; &#125;private void backtrack(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, int [] nums, int remain, int start)&#123; if(remain &lt; 0) return; else if(remain == 0) list.add(new ArrayList&lt;&gt;(tempList)); else&#123; for(int i = start; i &lt; nums.length; i++)&#123; if(i &gt; start &amp;&amp; nums[i] == nums[i-1]) continue; // skip duplicates tempList.add(nums[i]); backtrack(list, tempList, nums, remain - nums[i], i + 1); tempList.remove(tempList.size() - 1); &#125; &#125;&#125; Palindrome Partitioning : https://leetcode.com/problems/palindrome-partitioning/ public List&lt;List&lt;String&gt;&gt; partition(String s) { List&lt;List&lt;String&gt;&gt; list = new ArrayList&lt;&gt;(); backtrack(list, new ArrayList&lt;&gt;(), s, 0); return list; } public void backtrack(List&lt;List&lt;String&gt;&gt; list, List&lt;String&gt; tempList, String s, int start){ if(start == s.length()) list.add(new ArrayList&lt;&gt;(tempList)); else{ for(int i = start; i &lt; s.length(); i++){ if(isPalindrome(s, start, i)){ tempList.add(s.substring(start, i + 1)); backtrack(list, tempList, s, i + 1); tempList.remove(tempList.size() - 1); } } } } public boolean isPalindrome(String s, int low, int high){ while(low &lt; high) if(s.charAt(low++) != s.charAt(high--)) return false; return true; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>回溯法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码之StringBuffer,StringBuilder]]></title>
    <url>%2F2017%2F04%2F10%2FJava%E6%BA%90%E7%A0%81%E4%B9%8BStringBuffer-StringBuilder%2F</url>
    <content type="text"></content>
      <categories>
        <category>java源码</category>
      </categories>
      <tags>
        <tag>java源码</tag>
        <tag>StringBuffer</tag>
        <tag>StringBuilder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码之HashSet]]></title>
    <url>%2F2017%2F04%2F07%2FJava%E6%BA%90%E7%A0%81%E4%B9%8BHashSet%2F</url>
    <content type="text"><![CDATA[概述1.HashSet 是一个没有重复元素的集合。它是由HashMap实现的，不保证元素的顺序，特别是它不保证该顺序恒久不变。而且HashSet允许使用 null 元素。2.HashSet是非同步的。如果多个线程同时访问一个哈希 set，而其中至少一个线程修改了该 set，那么它必须保持外部同步。这通常是通过对自然封装该 set 的对象执行同步操作来完成的。如果不存在这样的对象，则应该使用 Collections.synchronizedSet 方法来“包装” Set。最好在创建时完成这一操作，以防止对该 set 进行意外的不同步访问：1Set s = Collections.synchronizedSet(new HashSet(...)); 3.HashSet通过iterator()返回的迭代器是fail-fast的。4.HashSet的继承关系如下：123public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable HashSet实现HashSet是基于HashMap实现的，底层使用HashMap来保存所有元素，相关HashSet的操作，基本上都是直接调用底层HashMap的相关方法来完成. HashSet属性12341. private transient HashMap&lt;E,Object&gt; map; 2. // Dummy value to associate with an Object in the backing Map 3. // 定义一个虚拟的Object对象作为HashMap的value，将此对象定义为static final。 4. private static final Object PRESENT = new Object(); 可以看到，HashSet 实际上是使用 HashMap 来保存数据的。而且主要用的是 HashMap的 key。PRESENT是什么东西呢？看上面的注释。dummy的意思是 挂名代表，傀儡。所以，可知：PRESENT是向map中插入key-value对应的value因为HashSet中只需要用到key，而HashMap是key-value键值对；所以，向map中添加键值对时，键值对的值固定是PRESENT。每个set集合中的元素都是HashMap的key 值（这也就保证了HashSet集合中不能有重复元素），而 它们的value值都是 PRESENT。 HashSet构造函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051521. /** 2. * 默认的无参构造器，构造一个空的HashSet。3. * 4. * 实际底层会初始化一个空的HashMap，并使用默认初始容量为16和加载因子0.75。 5. */ 6. public HashSet() &#123; 7. map = new HashMap&lt;E,Object&gt;(); 8. &#125; 9. /** 10. * 构造一个包含指定collection中的元素的新set。 11. * 实际底层使用默认的加载因子0.75和足以包含指定 12. * collection中所有元素的初始容量来创建一个HashMap。 13. * @param c 其中的元素将存放在此set中的collection。 14. */ 15. public HashSet(Collection&lt;? extends E&gt; c) &#123; 16. //为什么是Math.max((int) (c.size()/.75f) + 1, 16)？17. //实际上默认的HashMap的加载因子是0.75,c.size()/0.75 就是HashMap的实际容量，而 16 是默认的HashMap的初始容量。所以取两者的较大值作为 HashSet的容量。18. map = new HashMap&lt;E,Object&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); 19. // 使用Collection实现的Iterator迭代器，将集合c的元素一个个加入HashSet中20. addAll(c); 21. &#125; 22. /** 23. * 以指定的initialCapacity和loadFactor构造一个空的HashSet。 24. * 25. * 实际底层以以指定的initialCapacity和loadFactor构造一个空的HashMap。 26. * @param initialCapacity 初始容量。 27. * @param loadFactor 加载因子。 28. */ 29. public HashSet(int initialCapacity, float loadFactor) &#123; 30. map = new HashMap&lt;E,Object&gt;(initialCapacity, loadFactor); 31. &#125; 32. /** 33. * 以指定的initialCapacity构造一个空的HashSet。 34. * 35. * 实际底层以相应的参数及加载因子loadFactor为0.75构造一个空的HashMap。 36. * @param initialCapacity 初始容量。 37. */ 38. public HashSet(int initialCapacity) &#123; 39. map = new HashMap&lt;E,Object&gt;(initialCapacity); 40. &#125; 41. /** 42. * 以指定的initialCapacity和loadFactor构造一个新的空链接哈希集合。 43. * 此构造函数为包访问权限，不对外公开，实际只是是对LinkedHashSet的支持。 44. * 45. * 实际底层会以指定的参数构造一个空LinkedHashMap实例来实现。 46. * @param initialCapacity 初始容量。 47. * @param loadFactor 加载因子。 48. * @param dummy 标记。 没有实际意义49. */ 50. HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; 51. map = new LinkedHashMap&lt;E,Object&gt;(initialCapacity, loadFactor); 52. &#125; HashSet方法因为HashSet底层是HashMap实现，所以它的方法大都是直接调用HashMap的方法。 add(),remove()12345678910111. // 将元素(e)添加到HashSet中，也就是将元素作为Key放入HashMap中public boolean add(E e) &#123; 2. return map.put(e, PRESENT)==null; //可以看到PRESENT是value值。3. &#125; 4. // 删除HashSet中的元素(o)，其实是在HashMap中删除了以o为key的Entry5. public boolean remove(Object o) &#123; 6. return map.remove(o)==PRESENT; 7. &#125; 1. // 清空HashMap,的clear方法清空所有Entry2. public void clear() &#123;3. map.clear(); 4. &#125; 具体可参考HashMap的源码。 iterator(),size()，isEmpty()123456789101112131. public Iterator&lt;E&gt; iterator() &#123; 2. // 实际上返回的是HashMap的“key集合”的迭代器3. return map.keySet().iterator(); 4. &#125; 5. public int size() &#123; 6. return map.size(); 7. &#125; 8. public boolean isEmpty() &#123; 9. return map.isEmpty(); //查看map是否是空 10. &#125; 11. public boolean contains(Object o) &#123; 12. return map.containsKey(o); //map中是否包含键 0 13. &#125; 看名字很容易就知道是干嘛的，都是直接用的HashMap的方法。 clone()123456789101112131. /** 2. * 返回此HashSet实例的浅表副本：并没有复制这些元素本身。 3. * 底层实际调用HashMap的clone()方法，获取HashMap的浅表副本，并设置到 HashSet中。 4. */ 5. public Object clone() &#123; 6. try &#123; 7. HashSet&lt;E&gt; newSet = (HashSet&lt;E&gt;) super.clone(); 8. newSet.map = (HashMap&lt;E, Object&gt;) map.clone(); 9. return newSet; 10. &#125; catch (CloneNotSupportedException e) &#123; 11. throw new InternalError(e); 12. &#125; 13. &#125; 序列化123456789101112131415161718192021222324252627282930313233341. // java.io.Serializable的写入流中 2. // 将HashSet的“总的容量，加载因子，实际容量，所有的元素”都写入到输出流中 3. private void writeObject(java.io.ObjectOutputStream s) 4. throws java.io.IOException &#123; 5. // Write out any hidden serialization magic 6. s.defaultWriteObject(); 7. s.writeInt(map.capacity()); 8. s.writeFloat(map.loadFactor()); 9. // Write out size 10. s.writeInt(map.size()); 11. // Write out all elements in the proper order. 12. for (Iterator i=map.keySet().iterator(); i.hasNext(); ) 13. s.writeObject(i.next()); 14. &#125; 15. // java.io.Serializable 从流中读取 HashSet对象 16. // 将HashSet的“总的容量，加载因子，实际容量，所有的元素”依次读出 17. private void readObject(java.io.ObjectInputStream s) 18. throws java.io.IOException, ClassNotFoundException &#123; 19. // Read in any hidden serialization magic 20. s.defaultReadObject(); 21. 22. int capacity = s.readInt(); 23. float loadFactor = s.readFloat(); 24. map = (((HashSet)this) instanceof LinkedHashSet ? 25. new LinkedHashMap&lt;E,Object&gt;(capacity, loadFactor) : 26. new HashMap&lt;E,Object&gt;(capacity, loadFactor)); 27. // Read in size 28. int size = s.readInt(); 29. // Read in all elements in the proper order. 30. for (int i=0; i&lt;size; i++) &#123; 31. E e = (E) s.readObject(); 32. map.put(e, PRESENT); 33. &#125; 34. &#125; 总结 总体来说，HashSet是比较简单的，底层是HashMap实现的，使用的都是HashMap的方法。 HashSet遍历：12345678910 //遍历 2. Iterator iterator = set.iterator(); 3. while (iterator.hasNext()) &#123; 4. System.out.println(iterator.next()); 5. &#125; 6. 7. //或者这样 8. for (String s:set) &#123; 9. System.out.println(s); 10. &#125; 要注意的是：当我们要将一个类作为HashMap的key或者存储在HashSet的时候。通过重写hashCode()和equals(Object object)方法很重要，并且保证这两个方法的返回值一致。当两个类的hashCode()返回一致时，应该保证equasl()方法也返回true。HashMap源码整理中…]]></content>
      <categories>
        <category>java源码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>HashSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java源码之ArrayList]]></title>
    <url>%2F2017%2F04%2F06%2Fjava%E6%BA%90%E7%A0%81%E4%B9%8BArrayList%2F</url>
    <content type="text"><![CDATA[ArrayList概述：1public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable ArrayList是基于数组实现的，Object[] elementData;是一个动态数组，其容量能自动增长。ArrayList与Collection关系如下图： １．ArrayList不是线程安全的，只能用在单线程环境下，多线程环境下可以考虑用Collections.synchronizedList(List l)函数返回一个线程安全的ArrayList类，也可以使用concurrent并发包下的CopyOnWriteArrayList类。２．ArrayList实现了Serializable接口，因此它支持序列化，能够通过序列化传输，实现了RandomAccess接口，支持快速随机访问，实际上就是通过下标序号进行快速访问，实现了Cloneable接口，能被克隆。３．每个ArrayList实例都有一个容量，该容量是指用来存储列表元素的数组的大小。它总是至少等于列表的大小。随着向ArrayList中不断添加元素，其容量也自动增长。自动增长会带来数据向新数组的重新拷贝，因此，如果可预知数据量的多少，可在构造ArrayList时指定其容量。在添加大量元素前，应用程序也可以使用ensureCapacity操作来增加ArrayList实例的容量，这可以减少递增式再分配的数量。注意，此实现不是同步的。如果多个线程同时访问一个ArrayList实例，而其中至少一个线程从结构上修改了列表，那么它必须保持外部同步。 ArrayList的实现：对于ArrayList而言，它实现List接口、底层使用数组保存所有元素。其操作基本上是对数组的操作。下面我们来分析ArrayList的源代码： 私有属性：ArrayList定义只定义类两个私有属性：1234567891011/** * The array buffer into which the elements of the ArrayList are stored* The capacity of the ArrayList is the length of this array buffer. */ private transient Object[] elementData; /** * The size of the ArrayList (the number of elements it contains). * @serial */ private int size; 很容易理解，elementData存储ArrayList内的元素，size表示它包含的元素的数量。有个关键字需要解释：transient。Java的serialization提供了一种持久化对象实例的机制。当持久化对象时，可能有一个特殊的对象数据成员，我们不想用serialization机制来保存它。为了在一个特定对象的一个域上关闭serialization，可以在这个域前加上关键字transient。被标记为transient的属性在对象被序列化的时候不会被保存。接着回到ArrayList的分析中…… modCount和Array.copyof()，System.arraycopy。在父类AbstractList中定义了一个int型的属性：modCount，记录了ArrayList结构性变化的次数。1protected transient int modCount = 0; 在ArrayList的所有涉及结构变化的方法中都增加modCount的值，包括：add()、remove()、addAll()、removeRange()及clear()方法。这些方法每调用一次，modCount的值就加1。注：add()及addAll()方法的modCount的值是在其中调用的ensureCapacity()方法中增加的。然后，先了解一个方法，下面到处都会用到。Array.copyof()，System.arraycopy。1234567891011public static &lt;T&gt; T[] copyOf(T[] original, int newLength) &#123; return (T[]) copyOf(original, newLength, original.getClass()); &#125; public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] // 类型相同，则重新生成一个大小为newLength的数组实例 : (T[]) Array.newInstance(newType.getComponentType(), newLength); // 类型不同，重新生成一个大小为newLength的新类型数组实例 System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); //将原数组内容拷贝到新数组中,新数组取最小的数组长度 return copy; // 返回新数组的引用 &#125; 而其中的System.arraycopy(Object src, int srcPos, Object dest, int destPos, int length)的声明：123public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); src - 源数组。srcPos - 源数组中的起始位置。dest - 目标数组。destPos - 目标数据中的起始位置。length - 要复制的数组元素的数量。System.arraycopy是一个native方法，是底层使用c++实现的。 构造方法：ArrayList提供了三种方式的构造器，可以构造一个默认的空列表、构造一个指定初始容量的空列表以及构造一个包含指定collection的元素的列表，这些元素按照该collection的迭代器返回它们的顺序排列的。12345678910111213141516171819202122232425262728293031323334353637/** * Constructs an empty list with the specified initial capacity. */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //初始容量大于0,实例化数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; //初始容量为0 this.elementData = EMPTY_ELEMENTDATA; //空数组 &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125; /** ArrayList无参构造函数。 * Constructs an empty list with an initial capacity of ten. */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** 创建一个包含collection的ArrayList * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); //先转化成数组 if ((size = elementData.length) != 0) &#123; //如果集合不为空 // c.toArray might (incorrectly) not return Object[] if (elementData.getClass() != Object[].class) //给elementData 赋值 elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 如果是一个空的集合，用空数组来替换 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; 有参的两个构造器很好理解，下面说下无参的构造器。EMPTY_ELEMENTDATA是什么的？看名字就知道了，是一个空的数组。DEFAULTCAPACITY_EMPTY_ELEMENTDATA也是一个空数组。那么他们之间有什么区别呢？为什么ArrayList无参构造函数构造的是一个DEFAULTCAPACITY_EMPTY_ELEMENTDATA的空数组呢？因为以前的代码是直接初始化一个长度为10的数组。看上面的注释，我们可以知道，We distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when first element is added.就是当第一个元素被加入到elementData中时，区分这两者。123456789101112131415/** * 默认的初始容量为10 */ private static final int DEFAULT_CAPACITY = 10; /** * Shared empty array instance used for empty instances. */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * Shared empty array instance used for default sized empty instances. We * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when first element is added. */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; 既然如此，我们先看一下add() 123451. public boolean add(E e) &#123; 2. ensureCapacityInternal(size + 1); // Increments modCount!! 3. elementData[size++] = e; 4. return true; 5. &#125; 看第一行，应该就是区分的体现了，下面着重看下这个ensureCapacityInternal()函数。这涉及到下面的数组容量扩充，我们单独说一下。 调整数组容量ensureCapacity：与之前的ArrayList源码改变最大的就是这一部分了，先把三个调整容量的函数都贴出来，下面要多次用到。ensureCapacityInternal是第二个。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556571. /** 2. * Increases the capacity of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance, if 3. * necessary, to ensure that it can hold at least the number of elements 4. * specified by the minimum capacity argument. 5. * 6. * @param minCapacity the desired minimum capacity 7. */ 8. public void ensureCapacity(int minCapacity) &#123; 9. int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) 10. // any size if not default element table 11. ? 0 12. // larger than default for default empty table. It's already 13. // supposed to be at default size. 14. : DEFAULT_CAPACITY; 15. 16. if (minCapacity &gt; minExpand) &#123; 17. ensureExplicitCapacity(minCapacity); 18. &#125; 19. &#125; 20. 21. private void ensureCapacityInternal(int minCapacity) &#123; 22. if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; 23. minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); 24. &#125; 25. ensureExplicitCapacity(minCapacity); 26. &#125; 27. 28. private void ensureExplicitCapacity(int minCapacity) &#123; 29. modCount++; 30. if (minCapacity - elementData.length &gt; 0) 31. grow(minCapacity); 32. &#125; 1. /** 容量扩充，确保数组中至少能包含minimum capacity个元素2. * Increases the capacity to ensure that it can hold at least the 3. * number of elements specified by the minimum capacity argument. 4. * 5. * @param minCapacity the desired minimum capacity 6. */ 7. private void grow(int minCapacity) &#123; 8. int oldCapacity = elementData.length; 9. int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //原来容量的1.5倍 10. if (newCapacity - minCapacity &lt; 0) 11. newCapacity = minCapacity; 12. if (newCapacity - MAX_ARRAY_SIZE &gt; 0) 13. newCapacity = hugeCapacity(minCapacity); 14. // minCapacity is usually close to size, so this is a win: 15. elementData = Arrays.copyOf(elementData, newCapacity); 16. &#125; 17. //对大容量数组的处理18. private static int hugeCapacity(int minCapacity) &#123; 19. if (minCapacity &lt; 0) // overflow 20. throw new OutOfMemoryError(); 21. return (minCapacity &gt; MAX_ARRAY_SIZE) ? 22. Integer.MAX_VALUE : 23. MAX_ARRAY_SIZE; 24. &#125; 看ensureCapacityInternal中的下面这一句12333. if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; 34. minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); 35. &#125; 看到了吧，先比较DEFAULT_CAPACITY和minCapacity，取较大的值作为minCapacity，显然，对于无参的构造器的空数组，比较的结果是DEFAULT_CAPACITY(上面有定义是10)，然后接下来执行ensureExplicitCapacity(minCapacity)。再接下来，实际执行扩充的是grow(int minCapacity) 这个函数。上面如果是初始化的时候，容易计算此时的minCapacity = DEFAULT_CAPACITY = 10.所以执行grow的时候，121. if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; 会执行这一句，应该空的数组扩充1.5倍之后还是空的。接着往下看，就可以知道其实无参的ArrayList的构造器初始化的是一个长度为10的elementData 数组。 总结对于无参的ArrayList构造器，初始化的其实是一个容量为10的Object[] elementData 数组。每次执行扩充时，最终进行数组容量扩充的是grow（）函数，而且不难看出每次数组扩充后的容量为原来数组容量 的1.5倍。int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); 元素存储：ArrayList提供了set(int index, E element)、add(E e)、add(int index, E element)、addAll(Collection&lt;? extends E&gt; c)、addAll(int index, Collection&lt;? extends E&gt; c)这些添加元素的方法。下面我们一一讲解：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061621. //两个范围检验函数，查看索引是否越界，越界抛出异常 2. private void rangeCheck(int index) &#123; 3. if (index &gt;= size) 4. throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); 5. &#125; 6. private void rangeCheckForAdd(int index) &#123; 7. if (index &gt; size || index &lt; 0) 8. throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); 9. . &#125; 10. 11. // 用指定的元素替代此列表中指定位置上的元素，并返回以前位于该位置上的元素。 12. public E set(int index, E element) &#123; 13. RangeCheck(index); 14. E oldValue = (E) elementData[index]; 15. elementData[index] = element; 16. return oldValue; 17. &#125; 18. // 将指定的元素添加到此列表的尾部。 上面讲到过这个函数，实现也很简单 19. public boolean add(E e) &#123; 20. ensureCapacityInternal(size + 1); // Increments modCount!! 21. elementData[size++] = e; 22. return true; 23. &#125; 24. // 将指定的元素插入此列表中的指定位置。 25. // 如果当前位置有元素，则向右移动当前位于该位置的元素以及所有后续元素（将其索引加1）。 26. public void add(int index, E element) &#123; 27. rangeCheckForAdd(index);//索引范围检验 28. ensureCapacityInternal(size + 1); // 扩充1个单元 29. // 将 elementData中从Index位置开始、长度为size-index的元素， 30. // 拷贝到从下标为index+1位置开始的新的elementData数组中。 31. // 即将当前位于该位置的元素以及所有后续元素右移一个位置。 32. System.arraycopy(elementData, index, elementData, index + 1, 33. size - index); 34. elementData[index] = element;//插入元素 35. size++; 36. &#125; 37. 38. // 按照指定collection的迭代器所返回的元素顺序，将该collection中的所有元素添加到此列表的尾部。 39. public boolean addAll(Collection&lt;? extends E&gt; c) &#123; 40. Object[] a = c.toArray();//先转换成数组 41. int numNew = a.length; 42. ensureCapacityInternal(size + numNew); // 容量扩充 43. System.arraycopy(a, 0, elementData, size, numNew);//元素复制 44. size += numNew; 45. return numNew != 0; 46. &#125; 47. // 从指定的位置开始，将指定collection中的所有元素插入到此列表中。 48. public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; 49. rangeCheckForAdd(index);//索引检查 50. 51. Object[] a = c.toArray(); 52. int numNew = a.length; 53. ensureCapacityInternal(size + numNew); // 容量扩充 54. 55. int numMoved = size - index;//要移动的元素的个数 56. if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved);//复制元素 58. 59. System.arraycopy(a, 0, elementData, index, numNew); 60. size += numNew; 61. return numNew != 0; 62. &#125; ArrayList是基于数组实现的，可以看到上面的添加元素的方法，大都需要先进行索引检查（与操作索引相关的），还要进行数组容量的扩充，然后是 System.arraycopy复制元素。具体过程查看上面的注释。 元素读取：这个很简单，直接返回数组i位置上的元素即可。12345// 返回此列表中指定位置上的元素。 public E get(int index) &#123; RangeCheck(index); return (E) elementData[index]; &#125; 元素删除：ArrayList提供了根据下标或者指定对象两种方式的删除功能。如下： romove(int index):123456789101112// 移除此列表中指定位置上的元素。 public E remove(int index) &#123; RangeCheck(index); modCount++; E oldValue = (E) elementData[index]; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // Let gc do its work return oldValue; &#125; 首先是检查范围，修改modCount，保留将要被移除的元素，将移除位置之后的元素向前挪动一个位置，将list末尾元素置空（null），返回被移除的元素。 remove(Object o)1234567891011121314151617181920 // 移除此列表中首次出现的指定元素（如果存在）。这是应为ArrayList中允许存放重复的元素。 public boolean remove(Object o) &#123; // 由于ArrayList中允许存放null，因此下面通过两种情况来分别处理。 if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; // 类似remove(int index)，移除列表中指定位置上的元素。 fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; &#125; 首先通过代码可以看到，当移除成功后返回true，否则返回false。remove(Object o)中通过遍历element寻找是否存在传入对象，一旦找到就调用fastRemove移除对象。为什么找到了元素就知道了index，不通过remove(index)来移除元素呢？因为fastRemove跳过了判断边界的处理，因为找到元素就相当于确定了index不会超过边界，而且fastRemove并不返回被移除的元素。下面是fastRemove的代码，基本和remove(index)一致。方法说明：skips bounds checking and does notreturn the value removed.1234567private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // Let gc do its work &#125; batchRemove()123456789101112131415161718192021222324252627282930313233343536371. //保留集合c中的元素，集合外的元素全部删除2. Retains only the elements in this list that are contained in the3. * specified collection. In other words, removes from this list all4. * of its elements that are not contained in the specified collection.5. public boolean retainAll(Collection&lt;?&gt; c) &#123; 6. Objects.requireNonNull(c); 7. return batchRemove(c, true); 8. &#125; 9. 10. private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &#123; 11. final Object[] elementData = this.elementData; 12. int r = 0, w = 0; 13. boolean modified = false; 14. try &#123; 15. for (; r &lt; size; r++) 16. if (c.contains(elementData[r]) == complement) 17. elementData[w++] = elementData[r]; 18. &#125; finally &#123; 19. // Preserve behavioral compatibility with AbstractCollection, 20. // even if c.contains() throws. 21. if (r != size) &#123; 22. System.arraycopy(elementData, r, 23. elementData, w, 24. size - r); 25. w += size - r; 26. &#125; 27. if (w != size) &#123; 28. // clear to let GC do its work 29. for (int i = w; i &lt; size; i++) 30. elementData[i] = null; 31. modCount += size - w; 32. size = w; 33. modified = true; 34. &#125; 35. &#125; 36. return modified; 37. &#125; removeRange(int fromIndex,int toIndex)1234567891011 protected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // Let gc do its work int newSize = size - (toIndex-fromIndex); while (size != newSize) elementData[--size] = null; &#125; 执行过程是将elementData从toIndex位置开始的元素向前移动到fromIndex，然后将toIndex位置之后的元素全部置空顺便修改size。这个方法是protected，及受保护的方法，为什么这个方法被定义为protected呢？这是一个解释，但是可能不容易看明白。http://stackoverflow.com/questions/2289183/why-is-javas-abstractlists-removerange-method-protected先看下面这个例子 ArrayList ints = new ArrayList(Arrays.asList(0, 1, 2, 3, 4, 5, 6)); // fromIndex low endpoint (inclusive) of the subList // toIndex high endpoint (exclusive) of the subList ints.subList(2, 4).clear(); System.out.println(ints);输出结果是[0, 1, 4, 5, 6]，结果是不是像调用了removeRange(int fromIndex,int toIndex)！哈哈哈，就是这样的。但是为什么效果相同呢？是不是调用了removeRange(int fromIndex,int toIndex)呢？ArrayList和Vector区别：• ArrayList在内存不够时默认是扩展50% + 1个，Vector是默认扩展1倍。• Vector提供indexOf(obj, start)接口，ArrayList没有。• Vector属于线程安全级别的，但是大多数情况下不使用Vector，因为线程安全需要更大的系统开销。## trimToSizeArrayList还给我们提供了将底层数组的容量调整为当前列表保存的实际元素的大小的功能。它可以通过trimToSiz方法来实现。代码如下：12345678public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125; 由于elementData的长度会被拓展，size标记的是其中包含的元素的个数。所以会出现size很小但elementData.length很大的情况，将出现空间的浪费。trimToSize将返回一个新的数组给elementData，元素内容保持不变，length和size相同，节省空间。 转为静态数组toArray注意ArrayList的两个转化为静态数组的toArray方法。第一个， 调用Arrays.copyOf将返回一个数组，数组内容是size个elementData的元素，即拷贝elementData从0至size-1位置的元素到新数组并返回.1231. public Object[] toArray() &#123; 2. return Arrays.copyOf(elementData, size); 3. &#125; 第二个，如果传入数组的长度小于size，返回一个新的数组，大小为size，类型与传入数组相同。所传入数组长度与size相等，则将elementData复制到传入数组中并返回传入的数组。若传入数组长度大于size，除了复制elementData外，还将把返回数组的第size个元素置为空。123456789public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // Make a new array of a's runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; clone(),返回此 ArrayList 实例的浅表副本。（不复制这些元素本身。）调用父类的clone方法返回一个对象的副本，将返回对象的elementData数组的内容赋值为原对象elementData数组的内容，将副本的modCount设置为0。1234567891011public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; &#125; clear()123456789public void clear() &#123; modCount++; // Let gc do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; clear的时候并没有修改elementData的长度（好不容易申请、拓展来的，凭什么释放，留着搞不好还有用呢。这使得确定不再修改list内容之后最好调用trimToSize来释放掉一些空间），只是将所有元素置为null，size设置为0。 contains(Object)123public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0; &#125; 1.indexOf方法返回值与0比较来判断对象是否在list中。接着看indexOf。123456789101112public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; 2.lastIndexOf，光看名字应该就明白了返回的是传入对象在elementData数组中最后出现的index值123456789101112public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; 采用了从后向前遍历element数组，若遇到Object则返回index值，若没有遇到，返回-1. 序列化因为实现了java.io.Serializable接口，索引可以进行序列化操作。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Save the state of the &lt;tt&gt;ArrayList&lt;/tt&gt; instance to a stream (that * is, serialize it). 把arraylist实例写入一个流中 */ private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; /** * Reconstitute the &lt;tt&gt;ArrayList&lt;/tt&gt; instance from a stream (that is, * deserialize it). 从流中读出一个ArrayList实例 */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125; &#125; Fail-Fast机制：ArrayList也采用了快速失败的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。 ArrayList的遍历方式ArrayList支持3种遍历方式12345678910111213141516171、通过迭代器遍历：Iterator iter = list.iterator();while (iter.hasNext())&#123; System.out.println(iter.next());&#125; 2、随机访问，通过索引值去遍历，由于ArrayList实现了RandomAccess接口int size = list.size();for (int i=0; i&lt;size; i++) &#123; System.out.println(list.get(i)); &#125; 3、for循环遍历：for(String str:list)&#123; System.out.println(str);&#125; 总结:关于ArrayList的源码，给出几点比较重要的总结：1.注意其三个不同的构造方法。无参构造方法构造的ArrayList的容量默认为10，带有Collection参数的构造方法，将Collection转化为数组赋给ArrayList的实现数组elementData。2.注意扩充容量的方法ensureCapacity。ArrayList在每次增加元素（可能是1个，也可能是一组）时，都要调用该方法来确保足够的容量。当容量不足以容纳当前的元素个数时，就设置新的容量为旧的容量的1.5倍，如果设置后的新容量还不够，则直接新容量设置为传入的参数（也就是所需的容量），而后用Arrays.copyof()方法将元素拷贝到新的数组（详见下面的第3点）。从中可以看出，当容量不够时，每次增加元素，都要将原来的元素拷贝到一个新的数组中，非常之耗时，也因此建议在事先能确定元素数量的情况下，才使用ArrayList，否则建议使用LinkedList。3.ArrayList的实现中大量地调用了Arrays.copyof()和System.arraycopy()方法。我们有必要对这两个方法的实现做下深入的了解。首先来看Arrays.copyof()方法。它有很多个重载的方法，但实现思路都是一样的，我们来看泛型版本的源码： 1. public static &lt;T&gt; T[] copyOf(T[] original, int newLength) { 2. return (T[]) copyOf(original, newLength, original.getClass()); 3. } 很明显调用了另一个copyof方法，该方法有三个参数，最后一个参数指明要转换的数据的类型，其源码如下： 1. public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) { 2. T[] copy = ((Object)newType == (Object)Object[].class) 3. ? (T[]) new Object[newLength] 4. : (T[]) Array.newInstance(newType.getComponentType(), newLength); 5. System.arraycopy(original, 0, copy, 0, 6. Math.min(original.length, newLength)); 7. return copy; 8. } 这里可以很明显地看出，该方法实际上是在其内部又创建了一个长度为newlength的数组，调用System.arraycopy()方法，将原来数组中的元素复制到了新的数组中。下面来看System.arraycopy()方法。该方法被标记了native，调用了系统的C/C++代码，在JDK中是看不到的，但在openJDK中可以看到其源码。该函数实际上最终调用了C语言的memmove()函数，因此它可以保证同一个数组内元素的正确复制和移动，比一般的复制方法的实现效率要高很多，很适合用来批量处理数组。Java强烈推荐在复制大量数组元素时用该方法，以取得更高的效率。4.ArrayList基于数组实现，可以通过下标索引直接查找到指定位置的元素，因此查找效率高，但每次插入或删除元素，就要大量地移动元素，插入删除元素的效率低。5.在查找给定元素索引值等的方法中，源码都将该元素的值分为null和不为null两种情况处理，ArrayList中允许元素为null。6.数组扩容这是对ArrayList效率影响比较大的一个因素。每 当执行Add、AddRange、Insert、InsertRange等添加元素的方法，都会检查内部数组的容量是否不够了，如果是，它就会以当前容量 的两倍来重新构建一个数组，将旧元素Copy到新数组中，然后丢弃旧数组，在这个临界点的扩容操作，应该来说是比较影响效率的。由于是从word上粘贴过来的，格式有些不太正确，以后慢慢修改吧。]]></content>
      <categories>
        <category>java集合</category>
      </categories>
      <tags>
        <tag>java源码</tag>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Scanner next()和nextLine()]]></title>
    <url>%2F2017%2F04%2F02%2FJava-Scanner-next-%E5%92%8CnextLine%2F</url>
    <content type="text"><![CDATA[java中使用Scanner类获取数据输入十分方便，Scanner类中next()与nextLine()都可以实现字符串String的获取.它们的区别如下： next() 方法从第一个有效字符（非空格，非换行符），开始扫描。当遇见第一个分隔符或结束符(空格或换行符)时，结束扫描，获取扫描到的内容，即获得第一个扫描到的不含空格、换行符的单个字符串。 使用nextLine()时，则可以扫描到一行内容并作为一个字符串而被获取到。可以获取空格。 测试1234567891011121314public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); System.out.println("---&gt;Test1:\n"); String nextStr = scanner.next(); System.out.println("scanner.next()得到：" + nextStr); String nextlineStr = scanner.nextLine(); System.out.println("scanner.nextLine()得到：" + nextlineStr); System.out.println("\n---&gt;Test2:"); String nextlineStr2 = scanner.nextLine(); System.out.println("scanner.nextLine()得到：" + nextlineStr2); String nextStr2 = scanner.next(); System.out.println("scanner.next()得到：" + nextStr2); &#125; 结果]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Scanner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github上ssh配置]]></title>
    <url>%2F2017%2F03%2F31%2Fgithub%E4%B8%8Assh%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[配置 ssh key使用 git bash 生成 public ssh key，以下是最简单的方法12$ ssh-keygen -t rsaC/Documents and Settings/username/.ssh 目录下会生成 id_rsa.pub 将 id_rsa.pub 的内容完全复制到 github Account Setting 里的 ssh key 里即可 测试1$ ssh -T git@github.com 然后会看到1Hi [yourGithubAccount]! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 设置用户信息12$ git config --global user.name &quot;[yourName]&quot;//用户名$ git config --global user.email &quot;[yourEmail]&quot;//填写自己的邮箱 经过以上步骤，本机已成功连接到 github，为部署打下基础。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[栈与队列]]></title>
    <url>%2F2017%2F03%2F24%2F%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[题目描述用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型. 思路假设两个栈为A和B。 入队列的时候，只需要向A栈中入栈即可。 出队列的时候，要先检查B栈是否为空。如果B为空，把A栈中的元素全部放入B栈中。如果B不为空，就从B栈顶弹出一个元素。这样就实现了一个队列先进先出的功能。代码实现1234567891011121314151617181920212223242526272829303132/** * 用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。 * &lt;分析&gt;： * 入队：将元素进栈A * 出队：判断栈B是否为空，如果为空，则将栈A中所有元素pop，并push进栈B，栈B出栈； 如果不为空，栈B直接出栈。 * * @author XIAO * */import java.util.Stack;public class StackQueue &#123; Stack&lt;Integer&gt; stack1 = new Stack&lt;Integer&gt;(); Stack&lt;Integer&gt; stack2 = new Stack&lt;Integer&gt;(); public void push(int node) &#123; stack1.push(node); &#125; public int pop() &#123; int a; if (!stack2.isEmpty()) &#123; a = stack2.pop(); &#125; else &#123; while (!stack1.isEmpty()) &#123; stack2.push(stack1.pop()); &#125; a = stack2.pop(); &#125; return a; &#125;&#125; 题目描述用两个队列实现栈的功能。 思路把B当做一个中转站入栈：将元素进队列A出栈：判断队列A中元素的个数是否为1，如果等于1，则出队列，否则将队列A中的元素出队列并放入队列B，直到队列A中的元素留下一个，然后队列A出队列，再把队列B中的元素出队列以此放入队列A中。 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 用两个队列实现栈的功能； 思路 &lt;分析&gt;：把B当做一个中转站 入栈：将元素进队列A * 出栈：判断队列A中元素的个数是否为1，如果等于1，则出队列，否则将队列A中的元素出队列并放入队列B，直到队列A中的元素留下一 * 个，然后队列A出队列，再把 队列B中的元素出队列以此放入队列A中。 * * @author XIAO * */public class QueueStack &#123; Queue&lt;Integer&gt; queue1 = new ArrayDeque&lt;&gt;(); Queue&lt;Integer&gt; queue2 = new ArrayDeque&lt;&gt;(); public void push(int node) &#123; // 两个栈都为空时，优先考虑queue1 if (queue1.isEmpty() &amp;&amp; queue2.isEmpty()) &#123; queue1.add(node); return; &#125; // 如果queue1为空，queue2有元素，直接放入queue2 if (queue1.isEmpty()) &#123; queue2.add(node); return; &#125; if (queue2.isEmpty()) &#123; queue1.add(node); return; &#125; &#125; public int pop() &#123; // 两个栈都为空时，没有元素可以弹出 if (queue1.isEmpty() &amp;&amp; queue2.isEmpty()) &#123; try &#123; throw new Exception("stack is empty"); &#125; catch (Exception e) &#123; &#125; &#125; // 如果queue1为空，queue2有元素， 将queue2的元素依次放入queue1中，直到最后一个元素，我们弹出。 if (queue1.isEmpty()) &#123; while (queue2.size() &gt; 1) &#123; queue1.add(queue2.poll()); &#125; return queue2.poll(); &#125; if (queue2.isEmpty()) &#123; while (queue1.size() &gt; 1) &#123; queue2.add(queue1.poll()); &#125; return queue1.poll(); &#125; return (Integer) null; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>栈</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[青蛙跳台阶]]></title>
    <url>%2F2017%2F03%2F24%2F%E9%9D%92%E8%9B%99%E8%B7%B3%E5%8F%B0%E9%98%B6%2F</url>
    <content type="text"><![CDATA[题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 思路 假设第一次跳了一阶，那么还剩 n-1 阶，有f(n-1)中跳法。 假设第一次跳了2阶，那么还剩 n-2 阶，有f(n-2)中跳法。所以，这是一个斐波那契数列。f(n) = f(n-1)+f(n-2) 代码实现12345678910111213141516171819202122232425262728293031323334/** * 一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 * * 思路：假设第一次跳了一阶，那么还剩 n-1 阶，有f(n-1)中跳法。 * * 假设第一次跳了2阶，那么还剩 n-2 阶，有f(n-2)中跳法。 * * 所以，这是一个斐波那契数列。f(n) = f(n-1)+f(n-2) * * @author XIAO * */public class JumpFloor &#123; public int JumpFloorSolution(int target) &#123; if (target == 0) &#123; return 0; &#125; if (target == 1) &#123; return 1; &#125; if (target == 2) &#123; return 2; &#125; int f1 = 1; int f2 = 2; int cursum = 0; for (int i = 3; i &lt;= target; i++) &#123; cursum = f1 + f2; f1 = f2; f2 = cursum; &#125; return cursum; &#125;&#125; 题目2 一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 思路 假设第一次跳 1 阶。那么还剩 n-1 阶。一共还剩f(n-1)种跳法。 假设第一次跳 2 阶。那么还剩 n-2 阶。一共还剩f(n-2)种跳法。 。。。 假设第一次跳 n-1 阶。那么还剩 1 阶。一共还剩f(1)种跳法。 假设第一次跳 n 阶。一种跳法。 所以：f(n) = f(n-1)+f(n-2)+…+1; 而且:f(n-1) = f(n-2) +…+1; 所以f(n) = 2f(n-1) 代码实现1234567891011121314151617181920212223242526272829/** * 一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 * * 思路：同样：假设第一次跳 1 阶。那么还剩 n-1 阶。一共还剩f(n-1)种跳法。 * * 假设第一次跳 2 阶。那么还剩 n-2 阶。一共还剩f(n-2)种跳法。 。。。 * * 假设第一次跳 n-1 阶。那么还剩 1 阶。一共还剩f(1)种跳法。 * * 假设第一次跳 n 阶。一种跳法。 * * 所以：f(n) = f(n-1)+f(n-2)+...+1; 而且:f(n-1) = f(n-2) +...+1; * * 所以f(n) = 2f(n-1) * * @author XIAO * */public class JumoFloor2 &#123; public int JumpFloorSolution(int target) &#123; if (target &lt;= 0) &#123; return 0; &#125; if (target == 1) &#123; return 1; &#125; return JumpFloorSolution(target - 1) * 2; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵覆盖]]></title>
    <url>%2F2017%2F03%2F24%2F%E7%9F%A9%E9%98%B5%E8%A6%86%E7%9B%96%2F</url>
    <content type="text"><![CDATA[题目描述我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 思路有以下几种情形： target &lt;= 0 大矩形为&lt;= 2*0,直接return 0； target = 1大矩形为2*1，只有一种摆放方法，return1； target = 2 大矩形为2*2，有两种摆放方法，return2； target = n 分为两步考虑：第一次摆放一块 21 的小矩阵，则摆放方法总共为f(target - 1)√√第一次摆放一块1\2的小矩阵，则摆放方法总共为f(target-2)因为，摆放了一块1*2的小矩阵（用√√表示），对应下方的1*2（用××表示）摆放方法就确定了，所以为f(targte-2)√ √× ×所以：f(target) =f(target - 1) + f(targte-2)实际上就是一个斐波那契数列。 代码123456789101112131415public class Solution &#123; public int RectCover(int target) &#123; if(target==0)&#123; return 0; &#125; if(target==1)&#123; return 1; &#125; else if(target==2)&#123; return 2; &#125;else&#123; return RectCover(target-1)+RectCover(target-2); &#125; &#125; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何终止一个线程]]></title>
    <url>%2F2017%2F03%2F23%2F%E5%A6%82%E4%BD%95%E7%BB%88%E6%AD%A2%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[JAVA如何让一个线程死亡或结束&emsp;&emsp;不推荐使用stop()方法终止线程。，因为stop()方法容易引起死锁。12345678910111213141516171819202122232425262728291. /**2. * JAVA里面如何使用一个线程死亡或结束 *3. */4. public class T &#123;5. public static void main(String[] args) &#123;6. // 启动线程7. MyThread thread = new MyThread();8. new Thread(thread).start();9. 10. // 你的其它的工作，此时线程在运行中11. 12. // 你不想让线程干活了，停掉它13. // 注意，这只是一个标志，具体线程何时停，并不能精确控制14. thread.allDone = true;15. &#125;16. &#125;17. 18. class MyThread implements Runnable &#123;19. boolean **volatile** allDone = false;20. 21. public void run() &#123;22. // 每次循环都检测标志23. // 如果设置停止标志时已经在循环里24. // 则最长需要等待一个循环的时间才能终止25. while (!allDone) &#123;26. // 循环里的工作27. &#125;28. &#125;29. &#125; 使用 volatile 标识的变量具有线程可见性。当一个线程修改了这个变量的值，其他线程立即可以知道。所以可以避免多CPU出问题。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[求二叉树的深度]]></title>
    <url>%2F2017%2F03%2F21%2F%E6%B1%82%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%B7%B1%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。 # 思路 &emsp;&emsp;递归求解 # 代码 undefined &emsp;下面是一个跟上面类似的题目。 # 题目描述 &emsp;&emsp;判断一棵树是不是平衡二叉树。平衡二叉树指左右子树的高度不超过1的二叉树。思路很简单，直接贴代码。 代码12345678910111213141516171819202122232425262728293031/** * 判断一棵树是不是平衡二叉树 * * 思路：递归求左右子树的深度，比较判断是否是平衡二叉树 * * @author XIAO * */public class IsBalancedBinaryTree &#123; public boolean IsBalanced_Solution(TreeNode root) &#123; if (root == null) &#123; return true; &#125; int left = getDepth(root.left); int right = getDepth(root.right); if (Math.abs(left - right) &gt; 1) &#123; return false; &#125; return true; &#125; // 递归求解二叉树的深度 private int getDepth(TreeNode node) &#123; if (node == null) &#123; return 0; &#125; int left = getDepth(node.left); int right = getDepth(node.right); return left &gt; right ? left + 1 : right + 1; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一个只出现一次的字符]]></title>
    <url>%2F2017%2F03%2F21%2F%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E5%AD%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;在一个字符串(1&lt;=字符串长度&lt;=10000，全部由大写字母组成)中找到第一个只出现一次的字符,并返回它的位置. 思路&emsp;&emsp;暴力求解。 代码1234567891011121314151617181920212223242526272829303132333435/** * 在一个字符串(1&lt;=字符串长度&lt;=10000，全部由大写字母组成)中找到第一个只出现一次的字符,并返回它的位置 * * 思路：暴力求解 * * @author XIAO * */public class FirstNotRepeatingCharSolution &#123; public int FirstNotRepeatingChar(String str) &#123; if (str == null || str.length() == 0) &#123; return -1; &#125; // 用一个map记录每个字符出现的次数 HashMap&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; str.length(); i++) &#123; char c = str.charAt(i); if (map.containsKey(c)) &#123; int times = map.get(c); times += 1; map.put(c, times); &#125; else &#123; map.put(c, 1); &#125; &#125; // 出现一次的字符 首次出现的索引 for (int i = 0; i &lt; str.length(); i++) &#123; char c2 = str.charAt(i); if (map.get(c2) == 1) &#123; return i; &#125; &#125; return -1; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第N个丑数]]></title>
    <url>%2F2017%2F03%2F20%2F%E7%AC%ACN%E4%B8%AA%E4%B8%91%E6%95%B0%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;把只包含因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含因子7。习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。 思路&emsp;&emsp;暴力求解思路。首先我们要搞清楚怎么求丑数。ugly[]表示丑数数组。 ugly[0]=1; ugly[1]=1*2; ugly[3]=1*3; ugly[4]=122; ugly[5]=1*5; ugly[6]=123; …&emsp;&emsp;是不是可以找出规律来，我们需要记录 丑数中因子 2,3,5 出现的次数。具体用语言不好描述，可以看出规律。代码1234567891011121314151617181920212223242526272829303132333435/** * 把只包含因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含因子7。 * 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。 * * @author XIAO * */public class GetUglyNumber &#123; public int GetUglyNumber_Solution(int index) &#123; if (index &lt;= 0) &#123; return 0; &#125; int[] result = new int[index]; result[0] = 1; int i2 = 0, i3 = 0, i5 = 0;// i2,i3,i5分别记录丑数的因子中2,3,5的个数 for (int i = 1; i &lt; index; i++) &#123; result[i] = min(result[i2] * 2, min(result[i3] * 3, result[i5] * 5)); if (result[i] == result[i2] * 2) &#123; i2++; &#125; if (result[i] == result[i3] * 3) &#123; i3++; &#125; if (result[i] == result[i5] * 5) &#123; i5++; &#125; &#125; return result[index - 1]; &#125; private int min(int i, int j) &#123; return i &gt; j ? j : i; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把数组排成最小的数]]></title>
    <url>%2F2017%2F03%2F20%2F%E6%8A%8A%E6%95%B0%E7%BB%84%E6%8E%92%E6%88%90%E6%9C%80%E5%B0%8F%E7%9A%84%E6%95%B0%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。 解题思路&emsp;&emsp;不得不说，看了这题的解法，真的佩服！~&emsp;&emsp;先将整型数组转换成String数组，然后将String数组排序，最后将排好序的字符串数组拼接出来。关键就是制定排序规则。为什么需要定制排序，因为字符串 a和b 长度不等的情况。比如 “2” 和 “21” ,显然字符串”2”&lt;”21”,但是把他们链接起来的时候 221&gt;212.所以定制一种规则来排除这种情况。定制排序规则如下： 若ab &gt; ba 则 a &gt; b， 若ab &lt; ba 则 a &lt; b，若ab = ba 则 a = b；这个定制排序很妙！ 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。 * 例如输入数组&#123;3，32，321&#125;，则打印出这三个数字能排成的最小数字为321323。 * * 思路：真的思路太强。 * * 先将整型数组转换成String数组，然后将String数组排序，最后将排好序的字符串数组拼接出来。关键就是制定排序规则。 排序规则如下： 若ab &gt; * ba 则 a &gt; b， 若ab &lt; ba 则 a &lt; b， 若ab = ba 则 a = b； 解释说明： * 比如 "3" &lt;"31" 但是 * "331" &gt; "313"，所以要将二者拼接起来进行比较 * * @author XIAO * */public class MinNumberArray &#123; public String PrintMinNumber(int[] numbers) &#123; if (numbers == null || numbers.length == 0) &#123; return ""; &#125; int length = numbers.length; String[] strings = new String[length]; // 把整型数转换成字符串 for (int i = 0; i &lt; strings.length; i++) &#123; strings[i] = String.valueOf(numbers[i]); &#125; // 对字符串数组进行排序 Arrays.sort(strings, new Comparator&lt;String&gt;() &#123; @Override public int compare(String o1, String o2) &#123; String s1 = o1 + o2; String s2 = o2 + o1; return s1.compareTo(s2); &#125; &#125;); StringBuilder builder = new StringBuilder(); //把排序好的字符串拼接在一起 for (int i = 0; i &lt; strings.length; i++) &#123; builder.append(strings[i]); &#125; return builder.toString(); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[连续子数组的最大和]]></title>
    <url>%2F2017%2F03%2F19%2F%E8%BF%9E%E7%BB%AD%E5%AD%90%E6%95%B0%E7%BB%84%E7%9A%84%E6%9C%80%E5%A4%A7%E5%92%8C%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;在古老的一维模式识别中,常常需要计算连续子向量的最大和,当向量全为正数的时候,问题很好解决。但是,如果向量中包含负数,是否应该包含某个负数,并期望旁边的正数会弥补它呢？例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。你会不会被他忽悠住？(子向量的长度至少是1) 思路test]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo利用Github分支在不同电脑上写博客]]></title>
    <url>%2F2017%2F03%2F19%2FHexo%E5%88%A9%E7%94%A8Github%E5%88%86%E6%94%AF%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%94%B5%E8%84%91%E4%B8%8A%E5%86%99%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[利用github的不同分支来分别保存网站静态文件与hexo源码（md原始文件及主题等），实现在不同电脑上都可以自由写博客。 Github Page这里假设你已经在github上建好了page的仓库，也就是 “yourusername.github.io”的名字的项目仓库，比如我的 xiaoybboy.github.io 。另外，也假设你在自己的电脑上已经配置好git、hexo、node js等环境。 新建hexo分支仓库建好之后，都是默认一个master分支的，Github page要求你的网站文件必须存放在这个master分支上，这个没得选；所以我们需要新建另外一个分支来保存我们的hexo原始文件；master 保存的全是public 文件夹下的内容，这也是 hexo发布到github上的内容，而hexo这个分支，保存的是我们网站的配置 。1234git branch hexogit checkout hexogit add remote origin git@github.com:xiaoybboy/xiaoybboy.github.io.gitgit push -u origin hexo:hexo 设置默认分支因为我们写博客更多的是更新这个分支，网站文件所在的master分支则由hexo d命令发布文章的时候进行推送，所以我们将hexo分支设置为默认分支，这样我们在新的电脑环境下git clone该仓库时，自动切到hexo`分支。按下图进行操作。 配置hexo deploy参数为了保证hexo d命令可以正确部署到master分支，在hexo 的配置文件 _config.yml文件中配置参数如下：1234deploy: type: git repo: https://github.com/dxjia/xiaoybboy.github.io.git branch: master hexo 3.0之后，将github改为了git，这样适用性更广了，如果你发现无法hexo d，使用下面的命令安装git deployer插件后重试即可。1npm install hexo-deployer-git --save 修改推送到hexo分支上一步的deploy参数正确配置后，文章写完使用hexo g -d命令就可以直接部署了，生成的博客静态文件会自动部署到 username.github.io仓库的master分支上，这时候通过浏览器访问http://username.github.io就可以看到你的博客页面里。网站页面是保存了，但这时候我们还没有保存我们的hexo原始文件，包括我们的文章md文件，我们千辛万苦修改的主题配置等。。。接下来使用下面的步骤将他们都统统推送到hexo分支上去。其中目录下的.gitignore 表示哪些文件或文件夹不提交，根据自己需要配置。如果没有.git文件，先git init。123git add .git commit -m “change description”git push origin hexo 如果没关联远程仓库，执行第三步会出错。和远程仓库关联执行：git remote add origin &lt;远程仓库地址&gt;这样就OK了，我们的原始文件就都上去了，换电脑也不怕了。 日常写博客有时候我们可能会在不同的电脑上写博客，那在不同的电脑上配置 hexo、git、node.js，以及配置git ssh key等都要折腾一下的，这是免不了的，也是比wordpress等其他博客框架麻烦的一点。 已有环境如果在电脑上已经写过博客，那么可以在已有的工作目录下同步之前写的博客。在你的仓库目录下右键’git bash shell’，起来bash命令行，然后1git pull 这样你的状态就更新了，之后就是 hexo命令写文章啦。。。写完hexo g -d部署好后，使用123git add .git commit -m “change description”git push origin hexo 推送到hexo分支上去。 新的环境到了新的电脑上时，我们需要将项目先下载到本地，然后再进行hexo初始化。记住不需要hexo init指令12345git clone git@github.com:xiaoybboy/xiaoybboy.github.io.gitcd xiaoybboy.github.ionpm install hexonpm installnpm install hexo-deployer-git –save 之后开始写博客，写好部署好之后，别忘记 git add , ….git push origin hexo…推上去。。。原文地址：http://dxjia.cn/2016/01/27/hexo-write-everywhere/]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo提交新文章错误]]></title>
    <url>%2F2017%2F03%2F19%2Fhexo%E6%8F%90%E4%BA%A4%E6%96%B0%E6%96%87%E7%AB%A0%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[hexo提交新文章出错&emsp;&emsp;提交文章的时候报了下面这个错误，1234567891011121314151617181920212223ERROR Process failed: _posts/数组中出现次数超过一半的数字.mdYAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 5, column 1: ^ at generateError (F:\Myblog\hexo\node_modules\hexo\node_modules\js-yaml\lib\ js-yaml\loader.js:162:10) at throwError (F:\Myblog\hexo\node_modules\hexo\node_modules\js-yaml\lib\js- yaml\loader.js:168:9) at readBlockMapping (F:\Myblog\hexo\node_modules\hexo\node_modules\js-yaml\l ib\js-yaml\loader.js:1045:9) at composeNode (F:\Myblog\hexo\node_modules\hexo\node_modules\js-yaml\lib\js -yaml\loader.js:1331:12) at readDocument (F:\Myblog\hexo\node_modules\hexo\node_modules\js-yaml\lib\j s-yaml\loader.js:1493:3) at loadDocuments (F:\Myblog\hexo\node_modules\hexo\node_modules\js-yaml\lib\ js-yaml\loader.js:1549:5) at Object.load (F:\Myblog\hexo\node_modules\hexo\node_modules\js-yaml\lib\js -yaml\loader.js:1566:19) at parseYAML (F:\Myblog\hexo\node_modules\hexo\node_modules\hexo-front-matte r\lib\front_matter.js:80:21) at parse (F:\Myblog\hexo\node_modules\hexo\node_modules\hexo-front-matter\li b\front_matter.js:56:12) at F:\Myblog\hexo\node_modules\hexo\lib\plugins\processor\post.js:52:18 at tryCatcher (F:\Myblog\hexo\node_modules\hexo\node_modules\bluebird\js\rel ease\util.js:16:23) at Promise._settlePromiseFromHandler (F:\Myblog\hexo\node_modules\hexo\node_ modules\bluebird\js\release\promise.js:509:35) at Promise._settlePromise (F:\Myblog\hexo\node_modules\hexo\node_modules\blu ebird\js\release\promise.js:569:18) at Promise._settlePromise0 (F:\Myblog\hexo\node_modules\hexo\node_modules\bl uebird\js\release\promise.js:614:10) at Promise._settlePromises (F:\Myblog\hexo\node_modules\hexo\node_modules\bl uebird\js\release\promise.js:693:18) at Promise._fulfill (F:\Myblog\hexo\node_modules\hexo\node_modules\bluebird\ js\release\promise.js:638:18) at PromiseArray._resolve (F:\Myblog\hexo\node_modules\hexo\node_modules\blue bird\js\release\promise_array.js:126:19) at PromiseArray._promiseFulfilled (F:\Myblog\hexo\node_modules\hexo\node_mod ules\bluebird\js\release\promise_array.js:144:14) at PromiseArray._iterate (F:\Myblog\hexo\node_modules\hexo\node_modules\blue 仔细排查之后，发现是文章开头的categroies的冒号，写成了中文的冒号。额。。。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组中出现次数超过一半的数字]]></title>
    <url>%2F2017%2F03%2F19%2F%E6%95%B0%E7%BB%84%E4%B8%AD%E5%87%BA%E7%8E%B0%E6%AC%A1%E6%95%B0%E8%B6%85%E8%BF%87%E4%B8%80%E5%8D%8A%E7%9A%84%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。 思路&emsp;&emsp;对于这个问题提供两个解题思路。还有很多其他解法。 利用排序。先对数组进行排序，因为题目已知，有一个数字出现的次数超过了数组长度的一半。显然，排序完成之后中间的那个数组必定是这个数组。复杂度O(nlgn) 充分利用数组中有一个数字出现的次数超过数组长度的一半这个条件。这个数一定是相邻重复出现的次数最多的数。即使是最差情况，隔一个数插入这个数，最终这个数必定会出现在最后一位（还是因为出现次数大于数组长度的一半）。这个算法的复杂度只有O（n），不得不说，这个思路真的巧妙。代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组&#123;1,2,3,2,2,2,5,4,2&#125;。 * 由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。 * * 思路1：快速排序 思路2：找最大相邻重复出现的元素 * * @author XIAO * */public class MoreThanHalfNumArray &#123; /** * 第一种思路 * * @param array * @return */ public int MoreThanHalfNum_Solution(int[] array) &#123; // 判断数组长度是否为0或者数组为null if (array.length == 0 || array == null) return 0; Arrays.sort(array);// 快速排序对数组进行排序 int mid = array[(array.length) / 2];// 中间的元素 // 对mid 进行验证 int count = 0; for (int i = 0; i &lt; array.length; i++) &#123; if (mid == array[i]) &#123; count++; &#125; &#125; return count &gt; (array.length / 2) ? mid : 0; &#125; // 第二种思路，想了很久才想明白。关键是利用有一个数的出现次数大于数组长度的一半这个条件 public int MoreThanHalfNum_Solution2(int[] array) &#123; // 判断数组长度是否为0或者数组为null if (array.length == 0 || array == null) return 0; // 寻找相邻重复次数最多的元素 int temp = array[0];// 从第一个元素开始找 int times = 1;// 重复出现的次数 for (int i = 1; i &lt; array.length; i++) &#123; if (times == 0) &#123; temp = array[i];// 最后一次赋值的必定是我们要找的元素 times = 1; &#125; else if (array[i] == temp) &#123; times++; &#125; else &#123; times--; &#125; &#125; // 验证 int count = 0; for (int i = 0; i &lt; array.length; i++) &#123; if (array[i] == temp) &#123; count++; &#125; &#125; return count &gt; (array.length / 2) ? temp : 0; &#125;&#125; 总结&emsp;&emsp;总体来看，第一种方法比较容易想到，时间复杂度较高。第二种方法想了很久才想明白，哎，算法能力有待提高！时间复杂度才O(N)!其他还有很多方法，有待考虑。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[按字典序输出一个字符串的全排序]]></title>
    <url>%2F2017%2F03%2F18%2F%E6%8C%89%E5%AD%97%E5%85%B8%E5%BA%8F%E8%BE%93%E5%87%BA%E4%B8%80%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%85%A8%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。 思路&emsp;&emsp;大脑短路了，想明白这个竟然花了半小时。这个题目的核心其实是求解一个字符串的全排列。因为字典序只需要用Collection.sort()方法排序一个ArrayList 或者TreeSet就行了。&emsp;主要说下怎么对一个字符串进行全排列。比如说”abcd”怎么全排序呢?直觉告诉我们先把a放第一位，对”bcd”再进行全排列，就是一个递归。然后把b放在第一位，”acd”进行递归。…具体操作下面结合代码说。&emsp;下面就是对全排列的字符串进行排序操作，按字典序输出即可。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.util.ArrayList;import java.util.Collections;/** * 输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串 * abc,acb,bac,bca,cab和cba。 * * 思路：先求解字符串的全排列，然后对这些全排列进行排序。 * * @author XIAO * */public class StringPermutationSort &#123; public ArrayList&lt;String&gt; Permutation(String str) &#123; ArrayList&lt;String&gt; result = new ArrayList&lt;&gt;();// 保存全排列的结果 if (str != null &amp;&amp; str.length() &gt; 0) &#123;// 如果str不为空 Permutation(str.toCharArray(), 0, result);// 获取字符串的全排列 &#125; Collections.sort(result);// 对全排列的字符串进行排序 return result; &#125; /** * i 表示起始位置，从i这个位置开始向后寻找下面字符的全排列 * * @param charArray * @param i * @param result */ private void Permutation(char[] charArray, int i, ArrayList&lt;String&gt; result) &#123; // 如果 i 是最后一个字符位置 if (i == charArray.length - 1) &#123; result.add(String.valueOf(charArray));// 找到一个全排序 &#125; else &#123; for (int j = i; j &lt;= charArray.length - 1; j++) &#123; if (j != i &amp;&amp; charArray[j] == charArray[i])// 有重复字符时，跳过 continue; swap(charArray, i, j); Permutation(charArray, i + 1, result); swap(charArray, i, j); &#125; &#125; &#125; // 交换字符数组s的第i个位置和第j个位置的字符 private void swap(char[] s, int i, int j) &#123; if (s[i] == s[j]) &#123; ; &#125; else &#123; char c = s[i]; s[i] = s[j]; s[j] = c; &#125; &#125;&#125; &emsp;&emsp;回头再看究竟是怎么全排列的吧。就是这个函数 private void Permutation(char[] charArray, int i, ArrayList result) 的递归过程。其中 i 表示起始位置，从i这个位置开始向后寻找下面字符的全排列。当i == charArray.length - 1 时，表示已经到了最后一个字符，那么就找到了一个全排列。下面很好看懂，就是递归向下找，但是为什么要交换两次 charArray i和j 位置的字符呢？&emsp;&emsp;其实拿”abcd”来说，当我们交换 a和b 的位置（第一次交换），然后用b作为首字符寻找全排列。但是下次我们要交换 a和c 的位置，但是这时候 a和b 已经交换了，所以要把 a和b 换回来，才能保证每次交换的顺序没有乱。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉搜索树与双向链表]]></title>
    <url>%2F2017%2F03%2F18%2F%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E4%B8%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。 思路&emsp;&emsp;使用递归的思想。步骤如下：&emsp;1. 将左子树构造成双链表，并返回链表头节点。&emsp;2. 定位至左子树双链表最后一个节点。&emsp;3. 如果左子树链表不为空的话，将当前root追加到左子树链表。&emsp;4. 将右子树构造成双链表，并返回链表头节点。&emsp;5. 如果右子树链表不为空的话，将该链表追加到root节点之后。&emsp;6. 根据左子树链表是否为空确定返回的节点。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142/** * 输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。 * 思路：解题思路： 1.将左子树构造成双链表，并返回链表头节点。 2.定位至左子树双链表最后一个节点。 3.如果左子树链表不为空的话，将当前root追加到左子树链表。 4.将右子树构造成双链表，并返回链表头节点。 5.如果右子树链表不为空的话，将该链表追加到root节点之后。 6.根据左子树链表是否为空确定返回的节点。 * @author XIAO * */public class BinaryTreeLinkedList &#123; public TreeNode Convert(TreeNode root) &#123; if (root == null) &#123; return null; &#125; // 如果root的左右子树都为空 if (root.left == null &amp;&amp; root.right == null) &#123; return root; &#125; TreeNode left = Convert(root.left);// 把root节点的左子树转成链表，返回值为链表的头 TreeNode p = left; while (p != null &amp;&amp; p.right != null) &#123; p = p.right;// 循环定位到左子树双链表的最后一个节点 &#125; // 如果左子树链表不为空的话，将当前root追加到左子树链表 if (left != null) &#123; p.right = root;// 把root连接到左子树形成的双向链表中，双向链表，需要左右都连接 root.left = p; &#125; // 同样的，把根节点的右子树也形成双向链表，返回值为链表头 TreeNode right = Convert(root.right); // 把右子树的链表连接到上面的左子树和根节点的链表中 if (right != null) &#123; root.right = right;// 同样把右子树的链表连接上去 right.left = root; &#125; return left != null ? left : root; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树中和为某一值的路径]]></title>
    <url>%2F2017%2F03%2F18%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%AD%E5%92%8C%E4%B8%BA%E6%9F%90%E4%B8%80%E5%80%BC%E7%9A%84%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。 代码实现123456789101112131415public class Solution &#123; private ArrayList&lt;ArrayList&lt;Integer&gt;&gt; listAll = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); private ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; FindPath(TreeNode root,int target) &#123; if(root == null) return listAll; list.add(root.val); target -= root.val; if(target == 0 &amp;&amp; root.left == null &amp;&amp; root.right == null) listAll.add(new ArrayList&lt;Integer&gt;(list)); FindPath(root.left, target); FindPath(root.right, target); list.remove(list.size()-1);//返回父节点继续搜索 return listAll; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试字符串中是否包含重复字符]]></title>
    <url>%2F2017%2F03%2F18%2F%E6%B5%8B%E8%AF%95%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E6%98%AF%E5%90%A6%E5%8C%85%E5%90%AB%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[题目描述&emsp;&emsp;请实现一个算法，确定一个字符串的所有字符全都不同。要求不允许使用额外的存储空间。 思路&emsp;&emsp;暂时没想到好的思路，只能暴力求解。 代码实现12345678910public class StringRepeat &#123; // 暴力求解，双层循环，一一比较 public boolean checkDifferent(String iniString) &#123; for (int i = 0;i&lt;iniString.length();i++) &#123; for (int j = i+1;j&lt;iniString.length();j++) &#123; if (iniString.charAt(i) == iniString.charAt(j)) return false; &#125; &#125; return true;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F03%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
</search>
